{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def collect_data(main_folder):\n",
    "    \"\"\" Collects the minimum test loss and corresponding parameters across all subfolders in the main folder. \"\"\"\n",
    "    results = []\n",
    "    context_size = 0\n",
    "    # Traverse through each subfolder in the main folder\n",
    "    for subfolder in os.listdir(main_folder):\n",
    "        subfolder_path = os.path.join(main_folder, subfolder)\n",
    "        progress_file = os.path.join(subfolder_path, 'progress.csv')\n",
    "        params_file = os.path.join(subfolder_path, 'params.json')\n",
    "        \n",
    "        # Check if both necessary files exist\n",
    "        if os.path.exists(progress_file) and os.path.exists(params_file):\n",
    "            try:\n",
    "                # Read progress.csv and find the minimum test loss\n",
    "                data = pd.read_csv(progress_file)\n",
    "                data.fillna(0, inplace=True)\n",
    "                # Read params.json\n",
    "                with open(params_file, 'r') as file:\n",
    "                    params = json.load(file)\n",
    "                    # Collect required params and the corresponding test loss\n",
    "                    result = {}\n",
    "                    if 'master_neurons' in params:\n",
    "                        result['master_neurons'] = params.get('master_neurons')\n",
    "                    if 'context_store' in params:\n",
    "                        result['store_embedding_neurons'] = params.get('context_store')\n",
    "                    if 'context' in params:\n",
    "                        result['context_neurons'] = params.get('context')\n",
    "                    result['learning_rate'] = params.get('learning_rate')\n",
    "\n",
    "                    result['best_train_loss'] = data['train_loss'].min()\n",
    "                    result['dev_loss(at best_train)'] = data[data['train_loss'] == result['best_train_loss']]['dev_loss'].iloc[0]\n",
    "                    result['best_dev_loss'] = data['dev_loss'].min()\n",
    "                    result['train_loss(at best_dev)'] = data[data['dev_loss'] == result['best_dev_loss']]['train_loss'].iloc[0]\n",
    "                    results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing files in {subfolder_path}: {e}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "def create_results_table(main_folder, remove_dup_hyperparams = False):\n",
    "    \"\"\" Creates a table of the minimum test losses for each combination of learning_rate, context_size, and samples. \"\"\"\n",
    "    data = collect_data(main_folder)\n",
    "    if data:\n",
    "        # Create DataFrame from collected data\n",
    "        df = pd.DataFrame(data)\n",
    "        # Group by the parameters and find the row with the minimum dev_loss\n",
    "        columns_to_sort = ['master_neurons', 'store_embedding_neurons', 'context_neurons', 'learning_rate']\n",
    "        existing_columns = [col for col in columns_to_sort if col in df.columns]\n",
    "        sort_order = [True] * len(existing_columns)\n",
    "        sorted_result_df = df.sort_values(by=existing_columns, ascending=sort_order)\n",
    "        \n",
    "        if remove_dup_hyperparams == True:\n",
    "            sorted_result_df = sorted_result_df.drop_duplicates(subset=existing_columns, keep='first')\n",
    "        \n",
    "        pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "        return sorted_result_df\n",
    "        # print(sorted_result_df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"No data collected. Check the contents of your directories.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " store_embedding_neurons  context_neurons  learning_rate  best_train_loss  dev_loss(at best_train)  best_dev_loss  train_loss(at best_dev)\n",
      "                      16               16        0.00010       -371.07332               -318.13960     -320.26870               -370.46277\n",
      "                      16               16        0.00100       -363.71438               -303.73568     -322.61008               -361.45815\n",
      "                      16               16        0.00100       -371.31272               -324.28394     -325.36754               -368.90999\n",
      "                      16               32        0.00010       -380.89409               -332.31020     -333.39084               -380.47350\n",
      "                      16               64        0.00100       -388.41780               -340.98204     -343.72932               -385.36803\n",
      "                      16              128        0.01000       -309.59894               -286.68678     -286.68678               -309.59894\n",
      "                      16              128        0.10000       -250.51754               -255.67539     -255.67539               -250.51754\n",
      "                      16              256        0.00010       -380.27663               -339.88522     -341.62009               -378.61161\n",
      "                      16              256        0.01000       -387.33157               -341.57809     -349.46942               -384.43133\n",
      "                      32               16        0.00100       -396.31411               -319.20072     -352.66954               -382.75000\n",
      "                      32               32        0.00100       -351.59465               -293.44726     -293.44726               -351.59465\n",
      "                      32               32        0.00100       -375.51431               -331.82749     -332.29055               -371.63792\n",
      "                      32               32        0.01000       -388.81272               -337.05843     -348.49880               -386.73462\n",
      "                      32               64        0.00010       -382.45078               -335.60768     -337.38490               -378.14592\n",
      "                      32               64        0.00100       -359.56553               -312.68135     -325.14660               -354.09654\n",
      "                      32               64        0.01000       -371.73339               -334.55161     -337.22879               -371.40696\n",
      "                      32               64        0.01000       -384.02953               -344.27584     -344.27584               -384.02953\n",
      "                      32              128        0.00100       -385.04065               -345.99265     -346.90883               -382.61686\n",
      "                      32              128        0.00100       -382.08725               -341.99604     -343.59470               -378.31048\n",
      "                      32              256        0.00010       -361.31187               -317.45454     -318.01874               -359.08173\n",
      "                      32              256        0.00100       -358.85410               -320.93573     -327.94786               -358.13399\n",
      "                      32              256        0.00100       -365.51175               -330.66710     -334.33675               -363.97132\n",
      "                      32              256        0.01000       -343.57029               -298.24887     -309.56052               -343.47102\n",
      "                      64               16        0.00100       -394.09490               -348.06261     -353.04090               -391.84451\n",
      "                      64               32        0.00010       -253.69865               -182.63073     -182.63073               -253.69865\n",
      "                      64               32        0.00100       -352.62350               -308.87316     -311.49749               -345.16628\n",
      "                      64               32        0.01000       -377.67510               -336.84453     -336.89268               -375.38153\n",
      "                      64               64        0.00100       -378.36773               -337.78609     -339.57685               -377.09178\n",
      "                      64               64        0.01000       -353.66606               -293.01706     -318.52475               -353.63410\n",
      "                      64              128        0.00100       -358.90966               -325.88030     -328.07862               -358.12713\n",
      "                      64              128        0.01000       -352.77734               -320.89780     -323.97073               -348.84162\n",
      "                      64              256        0.00010       -258.28770               -177.35717     -178.58818               -257.83728\n",
      "                      64              256        0.00100       -387.64745               -344.23971     -346.71341               -385.00139\n",
      "                      64              256        0.00100       -360.40783               -327.48459     -328.92788               -359.47798\n",
      "                     128               16        0.00100       -387.72328               -331.29200     -345.69966               -386.83536\n",
      "                     128               16        0.01000       -296.93725               -214.81328     -216.31459               -294.39972\n",
      "                     128               32        0.00100       -368.62309               -325.27277     -330.94948               -358.28480\n",
      "                     128               64        0.00100       -356.52857               -304.42180     -312.03005               -354.05573\n",
      "                     128               64        0.00100       -393.18712               -356.13041     -359.31130               -393.02418\n",
      "                     128              128        0.00010       -391.44761               -349.49498     -350.94970               -390.76341\n",
      "                     128              128        0.00100       -365.24323               -328.49215     -330.48844               -364.56870\n",
      "                     128              128        0.01000       -386.55786               -341.26831     -347.38960               -380.73801\n",
      "                     128              256        0.00100       -360.79983               -327.48947     -330.67237               -359.44720\n",
      "                     128              256        0.01000       -388.91174               -345.03415     -346.73752               -386.02792\n",
      "                     128              256        0.01000       -341.54942               -298.33063     -298.33063               -341.54942\n",
      "                     256               16        0.00100       -381.92876               -340.62026     -342.93460               -379.95072\n",
      "                     256               32        0.00100       -363.77786               -311.38882     -321.06964               -361.70001\n",
      "                     256               32        0.01000       -388.21356               -342.41523     -347.39557               -378.02666\n",
      "                     256               64        0.00010       -263.52027               -159.31706     -160.44197               -261.91248\n",
      "                     256               64        0.00100       -379.78226               -337.74643     -339.65335               -378.04483\n",
      "                     256               64        0.00100       -363.83758               -319.66371     -320.51640               -355.24869\n",
      "                     256               64        0.01000       -285.91925               -103.43974     -246.71444               -253.34643\n",
      "                     256               64        0.01000       -379.91584               -337.84085     -342.53411               -378.39292\n",
      "                     256              128        0.01000       -390.07198               -349.77004     -350.29132               -387.68529\n",
      "                     256              256        0.00100       -379.62970               -339.48674     -339.97603               -379.51087\n",
      "                     256              256        0.01000       -386.00951               -343.12048     -345.78210               -383.17556\n"
     ]
    }
   ],
   "source": [
    "df = create_results_table('/user/ml4723/Prj/NIC/ray_results_real_symmetry_GNN_real_data/run_2024-07-18_05-16-26', True)\n",
    "df = df[(df['best_train_loss'] <= -250) | (df['best_dev_loss'] <= -250)]\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " master_neurons  learning_rate  best_train_loss  dev_loss(at best_train)  best_dev_loss  train_loss(at best_dev)\n",
      "             32        0.00010       -326.09080               -294.21318     -294.43363               -325.91324\n",
      "             32        0.00100       -399.60241               -356.28404     -358.72971               -397.63554\n",
      "             32        0.01000       -364.92925               -327.85471     -330.94319               -360.64344\n",
      "             64        0.00010       -366.55641               -327.64441     -328.10669               -365.93256\n",
      "             64        0.00100       -385.88158               -336.90190     -342.26485               -381.54177\n",
      "             64        0.01000       -396.50087               -347.48151     -356.73791               -395.11970\n",
      "            128        0.00010       -400.67679               -354.28443     -356.00071               -397.28431\n",
      "            128        0.00100       -411.46534               -340.93867     -352.29748               -402.07304\n",
      "            256        0.00010       -373.70624               -320.09718     -327.53072               -369.03133\n",
      "            256        0.00100       -420.54846               -326.16247     -356.51725               -393.41800\n",
      "            256        0.01000       -346.67603               -309.29875     -313.72243               -340.63322\n"
     ]
    }
   ],
   "source": [
    "df = create_results_table('/user/ml4723/Prj/NIC/ray_results_real_data_driven_net_real_data/run_2024-07-16_21-40-08', True)\n",
    "df = df[(df['best_train_loss'] <= -250) | (df['best_dev_loss'] <= -250)]\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "GNN_df = create_results_table('/user/ml4723/Prj/NIC/ray_results/real/GNN/run_2024-07-18_05-16-26', False)\n",
    "CTX_df = create_results_table('/user/ml4723/Prj/NIC/ray_results/real/ctx/run_2024-07-16_21-40-19', False)\n",
    "Vanilla_df = create_results_table('/user/ml4723/Prj/NIC/ray_results/real/vanilla/run_2024-07-16_21-40-08', False)\n",
    "BEN_df = create_results_table('/user/ml4723/Prj/NIC/ray_results/real/bench/run_2024-07-24_21-10-47', False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     type  best_train_loss dev_loss(at best_train)  best_dev_loss train_loss(at best_dev)\n",
      "   Oracle       -498.58855                    None     -460.50378                    None\n",
      "      GNN       -396.31411              -319.20072     -352.66954              -382.75000\n",
      "  Context       -423.62699              -321.39473     -351.54730              -405.59714\n",
      "  Vanilla       -429.19212              -317.88645     -356.51181              -396.97424\n",
      "Benchmark       -325.10248              -284.37065     -284.37065              -325.10248\n"
     ]
    }
   ],
   "source": [
    "gnn_df = pd.DataFrame(GNN_df.loc[GNN_df['best_train_loss'].idxmin()].drop(['store_embedding_neurons', 'context_neurons', 'learning_rate'])).T\n",
    "gnn_df.insert(0, 'type', 'GNN') \n",
    "ctx_df = pd.DataFrame(CTX_df.loc[CTX_df['best_train_loss'].idxmin()].drop(['learning_rate'])).T\n",
    "ctx_df.insert(0, 'type', 'Context') \n",
    "van_df = pd.DataFrame(Vanilla_df.loc[Vanilla_df['best_train_loss'].idxmin()].drop(['learning_rate', 'master_neurons'])).T\n",
    "van_df.insert(0, 'type', 'Vanilla') \n",
    "ben_df = pd.DataFrame(BEN_df.loc[BEN_df['best_train_loss'].idxmin()].drop(['learning_rate'])).T\n",
    "ben_df.insert(0, 'type', 'Benchmark') \n",
    "oracle_df = pd.DataFrame({'type': ['Oracle'], 'best_train_loss': [-498.58855], 'dev_loss(at best_train)': [None], 'best_dev_loss' : [-460.50378], 'train_loss(at best_dev)' : [None]})\n",
    "print(pd.concat([oracle_df, gnn_df, ctx_df, van_df, ben_df]).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('neural_inventory_control')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "295131613949c3a10f810057b447f8c1d2f9ae56e2b2c791b6162e59dbe65d0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
