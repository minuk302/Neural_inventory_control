{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To extend data one_store -> one_warehouse_stores setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shared_imports import *\n",
    "n_stores = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_and_save(path, n_stores):\n",
    "    data = torch.load(path)\n",
    "    data_extended = data.repeat(1, n_stores, 1)\n",
    "    torch.save(data_extended, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_and_save('data_files/favorita_one_warehouse/weekly_sales.pt', n_stores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on items that are sold at # of stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items sold in exactly 1 store(s): 10\n",
      "Number of items sold in exactly 2 store(s): 25\n",
      "Number of items sold in exactly 3 store(s): 46\n",
      "Number of items sold in exactly 4 store(s): 78\n",
      "Number of items sold in exactly 5 store(s): 117\n",
      "Number of items sold in exactly 6 store(s): 161\n",
      "Number of items sold in exactly 7 store(s): 174\n",
      "Number of items sold in exactly 8 store(s): 190\n",
      "Number of items sold in exactly 9 store(s): 234\n",
      "Number of items sold in exactly 10 store(s): 221\n",
      "Number of items sold in exactly 11 store(s): 270\n",
      "Number of items sold in exactly 12 store(s): 292\n",
      "Number of items sold in exactly 13 store(s): 315\n",
      "Number of items sold in exactly 14 store(s): 265\n",
      "Number of items sold in exactly 15 store(s): 226\n",
      "Number of items sold in exactly 16 store(s): 149\n",
      "Number of items sold in exactly 17 store(s): 122\n",
      "Number of items sold in exactly 18 store(s): 82\n",
      "Number of items sold in exactly 19 store(s): 41\n",
      "Number of items sold in exactly 20 store(s): 16\n",
      "Number of items sold in exactly 21 store(s): 4\n",
      "Number of items sold in exactly 22 store(s): 2\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'data_files/favorita_one_warehouse/tensors_row_info.csv'  # Update the file path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Group by 'item_nbr' and count unique 'store_nbr' for each 'item_nbr'\n",
    "store_counts = df.groupby('item_nbr')['store_nbr'].nunique()\n",
    "\n",
    "# Determine the maximum number of stores any item is sold in\n",
    "max_stores = store_counts.max()\n",
    "\n",
    "# Initialize a dictionary to store the counts\n",
    "store_distribution = {}\n",
    "\n",
    "# Loop through each unique store count found and count how many items have that store count\n",
    "for count in range(1, max_stores + 1):\n",
    "    store_distribution[count] = (store_counts == count).sum()\n",
    "\n",
    "ct = 0\n",
    "# Printing the results\n",
    "for stores, num_items in store_distribution.items():\n",
    "    ct += stores * num_items\n",
    "    print(f\"Number of items sold in exactly {stores} store(s): {num_items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct dataset from items being sold at 16 stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def filter_and_construct_data(csv_file_path, tensor_file_path, output_csv_path, output_tensor_path):\n",
    "    # Load the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Load the tensor\n",
    "    data_tensor = torch.load(tensor_file_path)\n",
    "    \n",
    "    # Find items sold in more than 16 different stores\n",
    "    store_counts = df.groupby('item_nbr')['store_nbr'].nunique()\n",
    "    items_more_than_16_stores = store_counts[store_counts >= 16].index\n",
    "    \n",
    "    # Filter DataFrame for these items\n",
    "    filtered_df = df[df['item_nbr'].isin(items_more_than_16_stores)]\n",
    "    \n",
    "    # For each qualifying item, select data for exactly 16 stores\n",
    "    final_df = pd.DataFrame()\n",
    "    indices = []\n",
    "    for item in items_more_than_16_stores:\n",
    "        temp_df = filtered_df[filtered_df['item_nbr'] == item]\n",
    "        selected_stores = temp_df['store_nbr'].drop_duplicates().iloc[:16]  # Select the first 16 unique stores\n",
    "        selected_rows = temp_df[temp_df['store_nbr'].isin(selected_stores)]\n",
    "        final_df = pd.concat([final_df, selected_rows])\n",
    "        indices.extend(selected_rows.index.tolist())\n",
    "    \n",
    "    # Select corresponding tensors\n",
    "    final_tensor = data_tensor[indices, :, :]\n",
    "    \n",
    "    # Ensure final_tensor is of the shape [X, 16, 240] where X is the number of valid (item, store) pairs\n",
    "    final_tensor = final_tensor.view(-1, 16, 240)\n",
    "    \n",
    "    # Save the new DataFrame and tensor\n",
    "    final_df.to_csv(output_csv_path, index=False)\n",
    "    torch.save(final_tensor, output_tensor_path)\n",
    "    \n",
    "    print(\"Filtered data has been saved successfully.\")\n",
    "\n",
    "# Usage\n",
    "filter_and_construct_data('data_files/favorita/tensors_row_info.csv', 'data_files/favorita/weekly_sales.pt'\\\n",
    "                          , 'data_files/favorita_one_warehouse/tensors_row_info.csv', 'data_files/favorita_one_warehouse/weekly_sales.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t= torch.load('data_files/favorita_one_warehouse/weekly_sales.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([416, 16, 240])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('neural_inventory_control')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "295131613949c3a10f810057b447f8c1d2f9ae56e2b2c791b6162e59dbe65d0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
