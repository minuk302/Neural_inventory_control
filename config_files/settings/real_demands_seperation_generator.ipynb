{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "config_files = [\n",
    "    \"n_warehouse_21_5_real_lost_demand\", \n",
    "    \"n_warehouse_21_4_real_lost_demand\", \n",
    "    \"n_warehouse_21_3_real_lost_demand\", \n",
    "    \"n_warehouse_21_2_real_lost_demand\"\n",
    "]\n",
    "\n",
    "for config_file in config_files:\n",
    "    with open(f'{config_file}.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    n_stores = config['problem_params']['n_stores']\n",
    "    n_warehouses = config['problem_params']['n_warehouses']\n",
    "    for store_idx in range(n_stores):\n",
    "        for warehouse_idx in range(n_warehouses):\n",
    "            config_copy = yaml.safe_load(yaml.dump(config))\n",
    "            config_copy['problem_params']['n_stores'] = 1\n",
    "            config_copy['problem_params']['n_warehouses'] = 1\n",
    "            \n",
    "            # save and load\n",
    "            config_copy['store_params']['demand']['file_location'] = f'/user/ml4723/Prj/NIC/data_files/favorita_{n_stores}_stores/separate/weekly_sales_{store_idx}.pt'\n",
    "            config_copy['store_params']['underage_cost']['file_location'] = f'/user/ml4723/Prj/NIC/data_files/favorita_{n_stores}_stores/separate/underage_costs_{store_idx}.pt'\n",
    "            config_copy['store_params']['holding_cost']['file_location'] = f'/user/ml4723/Prj/NIC/data_files/favorita_{n_stores}_stores/separate/holding_costs_{store_idx}.pt'\n",
    "\n",
    "\n",
    "            config_copy['store_params']['holding_cost']['sample_across_instances'] = False\n",
    "            config_copy['store_params']['holding_cost']['vary_across_samples'] = False\n",
    "            config_copy['store_params']['underage_cost']['sample_across_instances'] = False\n",
    "            config_copy['store_params']['underage_cost']['vary_across_samples'] = False\n",
    "\n",
    "            # Update warehouse specific parameters\n",
    "            config_copy['warehouse_params']['lead_time']['value'] = config['warehouse_params']['lead_time']['value'][warehouse_idx]\n",
    "            config_copy['warehouse_params']['holding_cost']['value'] = config['warehouse_params']['holding_cost']['value'][warehouse_idx]\n",
    "            config_copy['warehouse_params']['edge_initial_cost']['value'] = config['warehouse_params']['edge_initial_cost']['value'][warehouse_idx]\n",
    "            \n",
    "            if config['warehouse_params']['edges']['value'][warehouse_idx][store_idx] == 0:\n",
    "                continue\n",
    "            config_copy['warehouse_params']['edge_lead_times']['value'] = [[config['warehouse_params']['edge_lead_times']['value'][warehouse_idx][store_idx]]]\n",
    "            config_copy['warehouse_params']['edges']['value'] = [[config['warehouse_params']['edges']['value'][warehouse_idx][store_idx]]]\n",
    "            \n",
    "            # Save config\n",
    "            output_dir = f'/user/ml4723/Prj/NIC/config_files/settings/separate/{config_file}'\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            with open(f'{output_dir}/{store_idx}_{warehouse_idx}.yml', 'w') as file:\n",
    "                yaml.dump(config_copy, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Load the full tensors\n",
    "underage_costs = torch.load('/user/ml4723/Prj/NIC/data_files/favorita_21_stores/underage_costs.pt')\n",
    "holding_costs = torch.load('/user/ml4723/Prj/NIC/data_files/favorita_21_stores/holding_costs.pt')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/user/ml4723/Prj/NIC/data_files/favorita_21_stores/separate'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Split and save individual store data\n",
    "for store_idx in range(21):\n",
    "    # Split underage costs\n",
    "    store_underage = underage_costs[:, store_idx:store_idx+1]\n",
    "    torch.save(store_underage, os.path.join(output_dir, f'underage_costs_{store_idx}.pt'))\n",
    "    \n",
    "    # Split holding costs \n",
    "    store_holding = holding_costs[:, store_idx:store_idx+1]\n",
    "    torch.save(store_holding, os.path.join(output_dir, f'holding_costs_{store_idx}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Load the full tensor\n",
    "data = torch.load('/user/ml4723/Prj/NIC/data_files/favorita_21_stores/weekly_sales.pt')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/user/ml4723/Prj/NIC/data_files/favorita_21_stores/separate'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Split and save individual store data\n",
    "for store_idx in range(21):\n",
    "    store_data = data[:, store_idx:store_idx+1, :]  # Shape: (288, 1, ?)\n",
    "    output_path = os.path.join(output_dir, f'weekly_sales_{store_idx}.pt')\n",
    "    torch.save(store_data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n",
      "Processing config: n_warehouse_21_5_real_lost_demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17346/2922734437.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_warehouses = df.groupby('store_index').apply(lambda x: x.loc[x['Test Loss'].idxmin()][['store_index', 'warehouse_index', 'Test Loss']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'edges':\n",
      "    'value': [\n",
      "              [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "              [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "            ]\n",
      "  'edges_with_min_cost':\n",
      "    'value': [\n",
      "              [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "              [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "            ]\n",
      "\n",
      "Processing config: n_warehouse_21_4_real_lost_demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17346/2922734437.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_warehouses = df.groupby('store_index').apply(lambda x: x.loc[x['Test Loss'].idxmin()][['store_index', 'warehouse_index', 'Test Loss']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'edges':\n",
      "    'value': [\n",
      "              [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "              [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "            ]\n",
      "  'edges_with_min_cost':\n",
      "    'value': [\n",
      "              [0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "              [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "            ]\n",
      "\n",
      "Processing config: n_warehouse_21_3_real_lost_demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17346/2922734437.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_warehouses = df.groupby('store_index').apply(lambda x: x.loc[x['Test Loss'].idxmin()][['store_index', 'warehouse_index', 'Test Loss']])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  'edges':\n",
      "    'value': [\n",
      "              [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "              [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0] ,\n",
      "            ]\n",
      "  'edges_with_min_cost':\n",
      "    'value': [\n",
      "              [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "              [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] ,\n",
      "            ]\n",
      "\n",
      "Processing config: n_warehouse_21_2_real_lost_demand\n",
      "  'edges':\n",
      "    'value': [\n",
      "              [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1] ,\n",
      "              [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] ,\n",
      "            ]\n",
      "  'edges_with_min_cost':\n",
      "    'value': [\n",
      "              [1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1] ,\n",
      "              [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0] ,\n",
      "            ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17346/2922734437.py:55: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_warehouses = df.groupby('store_index').apply(lambda x: x.loc[x['Test Loss'].idxmin()][['store_index', 'warehouse_index', 'Test Loss']])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import analysis.ray_results_interpreter as rri\n",
    "import glob\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "config_files = [\n",
    "    \"n_warehouse_21_5_real_lost_demand\", \n",
    "    \"n_warehouse_21_4_real_lost_demand\", \n",
    "    \"n_warehouse_21_3_real_lost_demand\", \n",
    "    \"n_warehouse_21_2_real_lost_demand\"\n",
    "]\n",
    "\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "def custom_data_filler(out_row, reference_row):\n",
    "    out_row['path'] = reference_row['path']\n",
    "\n",
    "def default_condition_setter(condition_name):\n",
    "    return None\n",
    "\n",
    "sort_by = 'dev_loss'\n",
    "pick_row_from_run_by = 'dev_loss'\n",
    "\n",
    "for config_file in config_files:\n",
    "    print(f\"\\nProcessing config: {config_file}\")\n",
    "    with open(f'{config_file}.yml', 'r') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        \n",
    "    # Get the appropriate yml files for this config\n",
    "    base_path = f'/user/ml4723/Prj/NIC/config_files/settings/separate/{config_file}'\n",
    "    yml_files = []\n",
    "    if os.path.isdir(base_path):\n",
    "        for yml_file in glob.glob(os.path.join(base_path, '*.yml')):\n",
    "            yml_files.append(yml_file.split('settings/')[1].replace('.yml', ''))\n",
    "    \n",
    "    conditions = {\n",
    "        'config': yml_files,\n",
    "    }\n",
    "\n",
    "    df = results_interpretor.make_table({1: \"/user/ml4723/Prj/NIC/ray_results/separate_store/data_driven_net_n_warehouses_real\"},\n",
    "        conditions,\n",
    "        default_condition_setter,\n",
    "        custom_data_filler,\n",
    "        sort_by=sort_by,\n",
    "        pick_row_from_run_by=pick_row_from_run_by,\n",
    "        test_loss_limit=100)\n",
    "\n",
    "    # Extract store and warehouse indices from config column\n",
    "    df['store_index'] = df['config'].str.split('/').str[-1].str.split('_').str[0].astype(int)\n",
    "    df['warehouse_index'] = df['config'].str.split('/').str[-1].str.split('_').str[1].astype(int)\n",
    "\n",
    "    # Group by store_index and find warehouse with lowest dev loss for each store\n",
    "    best_warehouses = df.groupby('store_index').apply(lambda x: x.loc[x['Test Loss'].idxmin()][['store_index', 'warehouse_index', 'Test Loss']])\n",
    "    # print(\"\\nBest warehouse assignments by dev loss:\")\n",
    "    # print(best_warehouses)\n",
    "    \n",
    "    # Get best warehouse assignments from best_warehouses DataFrame\n",
    "    best_assignments = {}\n",
    "    for _, row in best_warehouses.iterrows():\n",
    "        store = row['store_index'] \n",
    "        warehouse = row['warehouse_index']\n",
    "        best_assignments[store] = warehouse\n",
    "\n",
    "    # Create new edge matrix with only best warehouse connections\n",
    "    n_warehouses = int(config_file.split('_')[3])\n",
    "    n_stores = 21\n",
    "    new_edges = [[0]*n_stores for _ in range(n_warehouses)]\n",
    "\n",
    "    for store in range(n_stores):\n",
    "        if store in best_assignments:\n",
    "            best_warehouse = int(best_assignments[store])  # Convert float to int\n",
    "            new_edges[best_warehouse][store] = 1\n",
    "    \n",
    "    print(\"  'edges':\")\n",
    "    print(\"    'value': [\")\n",
    "    for row in new_edges:\n",
    "        print(\"             \", row, \",\") \n",
    "    print(\"            ]\")\n",
    "\n",
    "    # Load the configuration data\n",
    "    edges = config['warehouse_params']['edges']['value']\n",
    "    edge_lead_times = config['warehouse_params']['edge_lead_times']['value']\n",
    "    edge_initial_costs = config['warehouse_params']['edge_initial_cost']['value']\n",
    "    \n",
    "    # Create new edge matrix with only lowest cost warehouse connections\n",
    "    n_warehouses = len(edges)\n",
    "    n_stores = len(edges[0])\n",
    "    min_cost_edges = [[0]*n_stores for _ in range(n_warehouses)]\n",
    "    \n",
    "    # For each store, find the warehouse with lowest edge_initial_cost\n",
    "    for store in range(n_stores):\n",
    "        min_cost = float('inf')\n",
    "        min_cost_warehouse = -1\n",
    "        \n",
    "        for warehouse in range(n_warehouses):\n",
    "            # Check if there's a connection and if the cost is lower\n",
    "            if edges[warehouse][store] == 1 and edge_initial_costs[warehouse] < min_cost:\n",
    "                min_cost = edge_initial_costs[warehouse]\n",
    "                min_cost_warehouse = warehouse\n",
    "        \n",
    "        # Set the connection for the lowest cost warehouse\n",
    "        if min_cost_warehouse != -1:\n",
    "            min_cost_edges[min_cost_warehouse][store] = 1\n",
    "    \n",
    "    print(\"  'edges_with_min_cost':\")\n",
    "    print(\"    'value': [\")\n",
    "    for row in min_cost_edges:\n",
    "        print(\"             \", row, \",\") \n",
    "    print(\"            ]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_inventory_control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
