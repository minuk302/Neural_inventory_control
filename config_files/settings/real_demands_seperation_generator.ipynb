{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "with open('n_warehouse_21_3_real_lost_demand_separate_example.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stores = 21\n",
    "n_warehouses = 3\n",
    "# Create separate configs for each store-warehouse combination\n",
    "for store_idx in range(n_stores):\n",
    "    for warehouse_idx in range(n_warehouses):\n",
    "        config_copy = yaml.safe_load(yaml.dump(config))\n",
    "        config_copy['store_params']['demand']['file_location'] = f'/user/ml4723/Prj/NIC/data_files/favorita_21_stores/separate/weekly_sales_{store_idx}.pt'\n",
    "        config_copy['store_params']['underage_cost']['file_location'] = f'/user/ml4723/Prj/NIC/data_files/favorita_21_stores/separate/underage_costs_{store_idx}.pt'\n",
    "        config_copy['store_params']['holding_cost']['file_location'] = f'/user/ml4723/Prj/NIC/data_files/favorita_21_stores/separate/holding_costs_{store_idx}.pt'\n",
    "\n",
    "        # Update warehouse specific parameters\n",
    "        config_copy['warehouse_params']['holding_cost']['value'] = config['warehouse_params']['holding_cost']['value'][warehouse_idx]\n",
    "        config_copy['warehouse_params']['edge_initial_cost']['value'] = config['warehouse_params']['edge_initial_cost']['value'][warehouse_idx]\n",
    "        \n",
    "        if config['warehouse_params']['edges']['value'][warehouse_idx][store_idx] == 0:\n",
    "            continue\n",
    "        config_copy['warehouse_params']['edge_lead_times']['value'] = [[config['warehouse_params']['edge_lead_times']['value'][warehouse_idx][store_idx]]]\n",
    "        config_copy['warehouse_params']['edges']['value'] = [[config['warehouse_params']['edges']['value'][warehouse_idx][store_idx]]]\n",
    "        \n",
    "        # Save config\n",
    "        output_dir = '/user/ml4723/Prj/NIC/config_files/settings/separate'\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        with open(f'{output_dir}/{store_idx}_{warehouse_idx}.yml', 'w') as file:\n",
    "            yaml.dump(config_copy, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('n_warehouse_21_3_real_lost_demand.yml', 'w') as file:\n",
    "    yaml.dump(config, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "underage_costs = torch.load('/user/ml4723/Prj/NIC/data_files/favorita_21_stores/underage_costs.pt')\n",
    "holding_costs = torch.load('/user/ml4723/Prj/NIC/data_files/favorita_21_stores/holding_costs.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Load the full tensors\n",
    "underage_costs = torch.load('/user/ml4723/Prj/NIC/data_files/favorita_21_stores/underage_costs.pt')\n",
    "holding_costs = torch.load('/user/ml4723/Prj/NIC/data_files/favorita_21_stores/holding_costs.pt')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/user/ml4723/Prj/NIC/data_files/favorita_21_stores/separate'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Split and save individual store data\n",
    "for store_idx in range(21):\n",
    "    # Split underage costs\n",
    "    store_underage = underage_costs[:, store_idx:store_idx+1]\n",
    "    torch.save(store_underage, os.path.join(output_dir, f'underage_costs_{store_idx}.pt'))\n",
    "    \n",
    "    # Split holding costs \n",
    "    store_holding = holding_costs[:, store_idx:store_idx+1]\n",
    "    torch.save(store_holding, os.path.join(output_dir, f'holding_costs_{store_idx}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Load the full tensor\n",
    "data = torch.load('/user/ml4723/Prj/NIC/data_files/favorita_21_stores/weekly_sales.pt')\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = '/user/ml4723/Prj/NIC/data_files/favorita_21_stores/separate'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Split and save individual store data\n",
    "for store_idx in range(21):\n",
    "    store_data = data[:, store_idx:store_idx+1, :]  # Shape: (288, 1, ?)\n",
    "    output_path = os.path.join(output_dir, f'weekly_sales_{store_idx}.pt')\n",
    "    torch.save(store_data, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/ml4723/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/user/ml4723/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best warehouse assignments by dev loss:\n",
      "             store_index  warehouse_index    Dev Loss\n",
      "store_index                                          \n",
      "0                      0                0 -734.874081\n",
      "1                      1                1 -150.253013\n",
      "2                      2                0 -386.780867\n",
      "3                      3                1 -394.398438\n",
      "4                      4                1 -120.980213\n",
      "5                      5                0 -171.394238\n",
      "6                      6                0 -269.323963\n",
      "7                      7                0 -217.438113\n",
      "8                      8                0 -269.214920\n",
      "9                      9                0 -259.378013\n",
      "10                    10                0 -217.708538\n",
      "11                    11                2 -217.735498\n",
      "12                    12                0 -265.235907\n",
      "13                    13                0 -194.272595\n",
      "14                    14                0 -795.323734\n",
      "15                    15                0 -746.673764\n",
      "16                    16                0 -737.428105\n",
      "17                    17                0 -484.717627\n",
      "18                    18                0 -584.202410\n",
      "19                    19                0 -400.197151\n",
      "20                    20                0 -448.652676\n",
      "  'edge_lead_times':\n",
      "    'value': [\n",
      "              [3, 3, 3, 4, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2] ,\n",
      "              [2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 4, 3, 4, 2, 2, 2, 2, 2, 2, 3] ,\n",
      "              [4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 4, 4, 4, 4, 4, 3, 2] ,\n",
      "            ]\n",
      "  'edges':\n",
      "    'value': [\n",
      "              [1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1] ,\n",
      "              [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "              [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0] ,\n",
      "            ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26030/3445438880.py:35: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  best_warehouses = df.groupby('store_index').apply(lambda x: x.loc[x['Dev Loss'].idxmin()][['store_index', 'warehouse_index', 'Dev Loss']])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import analysis.ray_results_interpreter as rri\n",
    "import glob\n",
    "yml_files = [path.split('settings/')[1].replace('.yml', '') for path in glob.glob('/user/ml4723/Prj/NIC/config_files/settings/separate/*.yml')]\n",
    "\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "def custom_data_filler(out_row, reference_row):\n",
    "    out_row['path'] = reference_row['path']\n",
    "\n",
    "def default_condition_setter(condition_name):\n",
    "    return None\n",
    "\n",
    "sort_by = 'train_loss'\n",
    "pick_row_from_run_by = 'train_loss'\n",
    "conditions = {\n",
    "    'config': yml_files,\n",
    "}\n",
    "\n",
    "df = results_interpretor.make_table({1: \"/user/ml4723/Prj/NIC/ray_results/separate_store/data_driven_net_n_warehouses_real\"},\n",
    "    conditions,\n",
    "    default_condition_setter,\n",
    "    custom_data_filler,\n",
    "    sort_by=sort_by,\n",
    "    pick_row_from_run_by=pick_row_from_run_by,\n",
    "    test_loss_limit=100)\n",
    "\n",
    "\n",
    "# Extract store and warehouse indices from config column\n",
    "df['store_index'] = df['config'].apply(lambda x: int(x.split('_')[0].split('/')[-1]))\n",
    "df['warehouse_index'] = df['config'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "# Group by store_index and find warehouse with lowest dev loss for each store\n",
    "best_warehouses = df.groupby('store_index').apply(lambda x: x.loc[x['Dev Loss'].idxmin()][['store_index', 'warehouse_index', 'Dev Loss']])\n",
    "print(\"\\nBest warehouse assignments by dev loss:\")\n",
    "print(best_warehouses)\n",
    "# Get best warehouse assignments from best_warehouses DataFrame\n",
    "best_assignments = {}\n",
    "for _, row in best_warehouses.iterrows():\n",
    "    store = row['store_index'] \n",
    "    warehouse = row['warehouse_index']\n",
    "    best_assignments[store] = warehouse\n",
    "\n",
    "# Create new edge matrix with only best warehouse connections\n",
    "n_warehouses = 3\n",
    "n_stores = 21\n",
    "new_edges = [[0]*n_stores for _ in range(n_warehouses)]\n",
    "edge_lead_times = [[3, 3, 3, 4, 3, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2],\n",
    "                   [2, 2, 2, 2, 2, 4, 3, 3, 3, 3, 3, 4, 3, 4, 2, 2, 2, 2, 2, 2, 3],\n",
    "                   [4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 4, 4, 4, 4, 4, 3, 2]]\n",
    "\n",
    "for store in range(n_stores):\n",
    "    if store in best_assignments:\n",
    "        best_warehouse = int(best_assignments[store])  # Convert float to int\n",
    "        new_edges[best_warehouse][store] = 1\n",
    "print(\"  'edge_lead_times':\")\n",
    "print(\"    'value': [\")\n",
    "for row in edge_lead_times:\n",
    "    print(\"             \", row, \",\")\n",
    "print(\"            ]\")\n",
    "print(\"  'edges':\")\n",
    "print(\"    'value': [\")\n",
    "for row in new_edges:\n",
    "    print(\"             \", row, \",\") \n",
    "print(\"            ]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_inventory_control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
