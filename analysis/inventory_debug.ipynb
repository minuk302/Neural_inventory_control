{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import ray_results_interpreter as rri\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "from main_run import MainRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/user/ml4723/Prj/NIC/ray_results/generic_architecture_n_warehouse/vanilla_n_warehouses/run_2025-02-21_18-11-35/run_3267f_00061_61_config=n_warehouse_lost_demand,dev_batch_size=32768,dev_n_samples=32768,early_stop_check_epochs=10,learning_rat_2025-02-21_18-11-36'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 15\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# base_path = \"/user/ml4723/Prj/NIC/ray_results/generic_architecture_n_warehouse/vanilla_n_warehouses/run_2025-02-21_18-11-35\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# for subdir in os.listdir(base_path):\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     subdir_path = os.path.join(base_path, subdir)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#         if os.path.exists(model_path):\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#             models.append(model_path)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m base_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/user/ml4723/Prj/NIC/ray_results/generic_architecture_n_warehouse/vanilla_n_warehouses/run_2025-02-21_18-11-35/run_3267f_00061_61_config=n_warehouse_lost_demand,dev_batch_size=32768,dev_n_samples=32768,early_stop_check_epochs=10,learning_rat_2025-02-21_18-11-36\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     17\u001b[0m         model_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/user/ml4723/Prj/NIC/ray_results/generic_architecture_n_warehouse/vanilla_n_warehouses/run_2025-02-21_18-11-35/run_3267f_00061_61_config=n_warehouse_lost_demand,dev_batch_size=32768,dev_n_samples=32768,early_stop_check_epochs=10,learning_rat_2025-02-21_18-11-36'"
     ]
    }
   ],
   "source": [
    "mode = \"test_on_dev\"\n",
    "setting_name = 'n_warehouse_lost_demand'\n",
    "\n",
    "models = []\n",
    "\n",
    "# base_path = \"/user/ml4723/Prj/NIC/ray_results/generic_architecture_n_warehouse/vanilla_n_warehouses/run_2025-02-21_18-11-35\"\n",
    "# for subdir in os.listdir(base_path):\n",
    "#     subdir_path = os.path.join(base_path, subdir)\n",
    "#     if os.path.isdir(subdir_path):\n",
    "#         model_path = os.path.join(subdir_path, \"model.pt\")\n",
    "#         if os.path.exists(model_path):\n",
    "#             models.append(model_path)\n",
    "\n",
    "base_path = \"/user/ml4723/Prj/NIC/ray_results/generic_architecture_n_warehouse/vanilla_n_warehouses/run_2025-02-21_18-11-35/run_3267f_00061_61_config=n_warehouse_lost_demand,dev_batch_size=32768,dev_n_samples=32768,early_stop_check_epochs=10,learning_rat_2025-02-21_18-11-36\"\n",
    "for file in os.listdir(base_path):\n",
    "    if file.endswith(\".pt\"):\n",
    "        model_path = os.path.join(base_path, file)\n",
    "        models.append(model_path)\n",
    "\n",
    "def run_main_run(model_path):\n",
    "    try:\n",
    "        # Extract hyperparam name from model path\n",
    "        hyperparam_name = model_path.split('/')[7]\n",
    "        print(f\"Running main_run.py for path {model_path}\")\n",
    "        cmd = [\n",
    "            \"/user/ml4723/.conda/envs/neural_inventory_control/bin/python\",\n",
    "            \"main_run.py\",\n",
    "            mode, # test or test_on_dev\n",
    "            setting_name,\n",
    "            hyperparam_name,\n",
    "            model_path,\n",
    "        ]\n",
    "        env = {\n",
    "            **os.environ,\n",
    "            \"MKL_THREADING_LAYER\": \"GNU\",\n",
    "            \"MKL_SERVICE_FORCE_INTEL\": \"1\"\n",
    "        }\n",
    "        subprocess.run(cmd, capture_output=True, text=True, check=True, env=env, cwd=\"/user/ml4723/Prj/NIC/\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running main_run.py for path {model_path}: {e}\")\n",
    "        print(f\"Error output: {e.stderr}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error running main_run.py for path {model_path}: {e}\")\n",
    "\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = []\n",
    "    for path in models:\n",
    "        while len(futures) >= 18:\n",
    "            done, not_done = concurrent.futures.wait(\n",
    "                futures, \n",
    "                return_when=concurrent.futures.FIRST_COMPLETED\n",
    "            )\n",
    "            futures = list(not_done)\n",
    "        futures.append(executor.submit(run_main_run, path))\n",
    "    concurrent.futures.wait(futures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/user/ml4723/Prj/NIC/ray_results/generic_architecture_n_warehouse/vanilla_n_warehouses/run_2025-02-21_18-11-35/run_3267f_00003_3_config=n_warehouse_lost_demand,dev_batch_size=32768,dev_n_samples=32768,early_stop_check_epochs=10,learning_rate_2025-02-21_18-11-36/model.pt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2689, 0.0000, 0.7311])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([1.0, float(\"-inf\"), 2.0])\n",
    "out = torch.softmax(x, dim=0)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_inventory_control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
