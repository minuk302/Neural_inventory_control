{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/ml4723/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/user/ml4723/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import ray_results_interpreter as rri\n",
    "import subprocess\n",
    "import concurrent.futures\n",
    "from main_run import MainRun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_data_and_plot(df, test_mode, setting_name, underage_cost):\n",
    "    def run_main_run(row):\n",
    "        try:\n",
    "            cmd = [\n",
    "                \"/user/ml4723/.conda/envs/neural_inventory_control/bin/python\",\n",
    "                \"main_run.py\",\n",
    "                test_mode, # test or test_on_dev\n",
    "                setting_name,\n",
    "                row['hyperparam_name'],\n",
    "                row['path'],\n",
    "                row['Architecture Class']\n",
    "            ]\n",
    "            env = {\n",
    "                **os.environ,\n",
    "                \"MKL_THREADING_LAYER\": \"GNU\",\n",
    "                \"MKL_SERVICE_FORCE_INTEL\": \"1\"\n",
    "            }\n",
    "            subprocess.run(cmd, capture_output=True, text=True, check=True, env=env, cwd=\"/user/ml4723/Prj/NIC/\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error running main_run.py for path {row['path']}: {e}\")\n",
    "            print(f\"Error output: {e.stderr}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error running main_run.py for path {row['path']}: {e}\")\n",
    "\n",
    "    def get_file_name(row):\n",
    "        return f\"results/one_warehouse_real/{row['# of stores']}/{row['Architecture Class']}/{underage_cost}.csv\"\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        futures = []\n",
    "        for _, row in df.iterrows():\n",
    "            file_name = get_file_name(row)\n",
    "            if os.path.exists(file_name):\n",
    "                continue\n",
    "            while len(futures) >= 24:\n",
    "                done, not_done = concurrent.futures.wait(\n",
    "                    futures, \n",
    "                    return_when=concurrent.futures.FIRST_COMPLETED\n",
    "                )\n",
    "                futures = list(not_done)\n",
    "            futures.append(executor.submit(run_main_run, row))\n",
    "        concurrent.futures.wait(futures)\n",
    "    \n",
    "    avg_s_underage = []\n",
    "    avg_s_holding = []\n",
    "    avg_w_holding = []\n",
    "    avg_cost = []\n",
    "    for _, row in df.iterrows():\n",
    "        file_name = get_file_name(row)\n",
    "        data = pd.read_csv(file_name)\n",
    "        n_samples = 32768\n",
    "        batch_size = 4096\n",
    "        num_batches = n_samples // batch_size\n",
    "        num_steps = 500\n",
    "        start_step = 300\n",
    "        \n",
    "        relevant_indices = []\n",
    "        for batch in range(num_batches):\n",
    "            batch_start = batch * batch_size * num_steps\n",
    "            step_start = batch_start + start_step * batch_size\n",
    "            step_end = batch_start + num_steps * batch_size\n",
    "            relevant_indices.extend(range(step_start, step_end))\n",
    "        relevant_data = data.iloc[relevant_indices]\n",
    "        \n",
    "        n_stores = row['# of stores']\n",
    "        avg_s_underage.append(relevant_data['s_underage_costs'].mean() / underage_cost)\n",
    "        avg_s_holding.append(relevant_data['s_holding_costs'].mean() / underage_cost)\n",
    "        avg_w_holding.append(relevant_data['w_holding_costs'].mean() / underage_cost)\n",
    "        avg_cost.append(relevant_data['s_underage_costs'].sum() * n_stores + relevant_data['s_holding_costs'].sum() * n_stores + relevant_data['w_holding_costs'].sum())\n",
    "\n",
    "    # Create a copy of the dataframe to avoid SettingWithCopyWarning\n",
    "    df_copy = df.copy()\n",
    "    df_copy['avg_s_underage'] = avg_s_underage\n",
    "    df_copy['avg_s_holding'] = avg_s_holding\n",
    "    df_copy['avg_w_holding'] = avg_w_holding \n",
    "    df_copy['avg_cost'] = avg_cost\n",
    "    df = df_copy\n",
    "\n",
    "    # Calculate relative cost\n",
    "    # Calculate cost as percentage of lowest cost\n",
    "    # Calculate min cost for each number of stores\n",
    "    df['cost'] = df.groupby('# of stores')['avg_cost'].transform(lambda x: x/x.min() * 100)\n",
    "\n",
    "    plot_data = df.pivot(index=\"# of stores\", columns='Architecture Class', \n",
    "                         values=['cost', 'avg_s_underage', 'avg_s_holding', 'avg_w_holding'])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(20, 12))\n",
    "    axes = axes.flatten()  # Flatten the 2D array of axes to 1D for easier iteration\n",
    "    titles = ['Cost (% of minimum at each # of stores)', 'Average Store lost sales / (average unit underage cost)', 'Average Store Holding Cost / (average unit underage cost)', 'Average Warehouse Holding Cost / (average unit underage cost)']\n",
    "    y_values = ['cost', 'avg_s_underage', 'avg_s_holding', 'avg_w_holding']\n",
    "\n",
    "    x_values = df['# of stores'].unique()\n",
    "    for i, (ax, title, y_value) in enumerate(zip(axes, titles, y_values)):\n",
    "        for arch in df['Architecture Class'].unique():\n",
    "            if arch == 'Just_In_Time':\n",
    "                continue\n",
    "            if arch in plot_data[y_value].columns:\n",
    "                ax.plot(x_values, plot_data[y_value][arch].loc[x_values], marker='o', label=f'{arch}', \n",
    "                        color=color_scheme[arch], linestyle=linestyle_scheme[arch])\n",
    "        \n",
    "        ax.set_xlabel('Number of stores')\n",
    "        ax.set_ylabel(f'{title}')\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_xticks(x_values)\n",
    "        ax.set_xticklabels(x_values)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/3/run_2024-12-29_14-32-04/run_95668_00003_3_config=transshipment_backlogged,early_stop_check_epochs=25,samples=1,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-32-04: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/3/run_2024-12-29_14-32-04/run_95668_00002_2_config=transshipment_backlogged,early_stop_check_epochs=25,samples=3,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-32-04: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/3/run_2024-12-29_14-32-04/run_95668_00001_1_config=transshipment_backlogged,early_stop_check_epochs=25,samples=2,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-32-04: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/3/run_2024-12-29_14-32-04/run_95668_00000_0_config=transshipment_backlogged,early_stop_check_epochs=25,samples=1,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-32-04: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/5/run_2024-12-29_14-33-57/run_d887a_00001_1_config=transshipment_backlogged,early_stop_check_epochs=25,samples=2,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-33-57: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/5/run_2024-12-29_14-33-57/run_d887a_00003_3_config=transshipment_backlogged,early_stop_check_epochs=25,samples=1,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-33-57: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/5/run_2024-12-29_14-33-57/run_d887a_00002_2_config=transshipment_backlogged,early_stop_check_epochs=25,samples=3,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-33-57: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/5/run_2024-12-29_14-33-57/run_d887a_00000_0_config=transshipment_backlogged,early_stop_check_epochs=25,samples=1,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-33-57: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/10/run_2024-12-29_14-34-09/run_e0135_00002_2_config=transshipment_backlogged,early_stop_check_epochs=25,samples=3,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-34-09: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/10/run_2024-12-29_14-34-09/run_e0135_00003_3_config=transshipment_backlogged,early_stop_check_epochs=25,samples=1,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-34-09: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/10/run_2024-12-29_14-34-09/run_e0135_00001_1_config=transshipment_backlogged,early_stop_check_epochs=25,samples=2,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-34-09: 'test_loss'\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/generic_architecture_transshipment/vanilla_transshipment/10/run_2024-12-29_14-34-09/run_e0135_00000_0_config=transshipment_backlogged,early_stop_check_epochs=25,samples=1,stop_if_no_improve_for_epochs=100,store_lea_2024-12-29_14-34-09: 'test_loss'\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLossySetitemError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/indexes/base.py:5309\u001b[0m, in \u001b[0;36mIndex._validate_fill_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5308\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 5309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp_can_hold_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5310\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m LossySetitemError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5311\u001b[0m     \u001b[38;5;66;03m# re-raise as TypeError for consistency\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1856\u001b[0m, in \u001b[0;36mnp_can_hold_element\u001b[0;34m(dtype, element)\u001b[0m\n\u001b[1;32m   1854\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m element\n\u001b[0;32m-> 1856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LossySetitemError\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mLossySetitemError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/indexes/base.py:6988\u001b[0m, in \u001b[0;36mIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   6987\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 6988\u001b[0m         item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_fill_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6989\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, LossySetitemError):\n\u001b[1;32m   6990\u001b[0m     \u001b[38;5;66;03m# e.g. trying to insert an integer into a DatetimeIndex\u001b[39;00m\n\u001b[1;32m   6991\u001b[0m     \u001b[38;5;66;03m#  We cannot keep the same dtype, so cast to the (often object)\u001b[39;00m\n\u001b[1;32m   6992\u001b[0m     \u001b[38;5;66;03m#  minimal shared dtype before doing the insert.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/indexes/base.py:5312\u001b[0m, in \u001b[0;36mIndex._validate_fill_value\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5310\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m LossySetitemError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   5311\u001b[0m         \u001b[38;5;66;03m# re-raise as TypeError for consistency\u001b[39;00m\n\u001b[0;32m-> 5312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   5313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m can_hold_element(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values, value):\n",
      "\u001b[0;31mTypeError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 59\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m correlation \u001b[38;5;129;01min\u001b[39;00m params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstores_correlation\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     52\u001b[0m     df \u001b[38;5;241m=\u001b[39m results_interpretor\u001b[38;5;241m.\u001b[39mmake_table(paths,\n\u001b[1;32m     53\u001b[0m         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_lead_time\u001b[39m\u001b[38;5;124m'\u001b[39m: lead_time,\n\u001b[1;32m     54\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_underage_cost\u001b[39m\u001b[38;5;124m'\u001b[39m: underage_cost,\n\u001b[1;32m     55\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstores_correlation\u001b[39m\u001b[38;5;124m'\u001b[39m: correlation},\n\u001b[1;32m     56\u001b[0m         default_condition_setter, custom_data_filler, \n\u001b[1;32m     57\u001b[0m         sort_by\u001b[38;5;241m=\u001b[39msort_by, pick_row_from_run_by\u001b[38;5;241m=\u001b[39mpick_row_from_run_by)\n\u001b[0;32m---> 59\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mArchitecture Class\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43march_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     df\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyperparam_name\u001b[39m\u001b[38;5;124m'\u001b[39m, arch_name)\n\u001b[1;32m     61\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_lead_time\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lead_time\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/frame.py:5172\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   5169\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   5171\u001b[0m value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m-> 5172\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/internals/managers.py:1365\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value, refs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m   1359\u001b[0m     \u001b[38;5;66;03m# TODO: re-issue this with setitem-specific message?\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[1;32m   1361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1362\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe behavior of Index.insert with object-dtype is deprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1363\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1364\u001b[0m     )\n\u001b[0;32m-> 1365\u001b[0m     new_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1368\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/indexes/range.py:936\u001b[0m, in \u001b[0;36mRangeIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m    933\u001b[0m         new_rng \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop, step)\n\u001b[1;32m    934\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_simple_new(new_rng, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/indexes/base.py:6994\u001b[0m, in \u001b[0;36mIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   6989\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m, LossySetitemError):\n\u001b[1;32m   6990\u001b[0m     \u001b[38;5;66;03m# e.g. trying to insert an integer into a DatetimeIndex\u001b[39;00m\n\u001b[1;32m   6991\u001b[0m     \u001b[38;5;66;03m#  We cannot keep the same dtype, so cast to the (often object)\u001b[39;00m\n\u001b[1;32m   6992\u001b[0m     \u001b[38;5;66;03m#  minimal shared dtype before doing the insert.\u001b[39;00m\n\u001b[1;32m   6993\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_common_type_compat(item)\n\u001b[0;32m-> 6994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   6997\u001b[0m     item, (\u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mdatetime64, np\u001b[38;5;241m.\u001b[39mtimedelta64)\n\u001b[1;32m   6998\u001b[0m ):\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;66;03m# with object-dtype we need to worry about numpy incorrectly casting\u001b[39;00m\n\u001b[1;32m   7000\u001b[0m     \u001b[38;5;66;03m# dt64/td64 to integer, also about treating tuples as sequences\u001b[39;00m\n\u001b[1;32m   7001\u001b[0m     \u001b[38;5;66;03m# special-casing dt64/td64 https://github.com/numpy/numpy/issues/12550\u001b[39;00m\n\u001b[1;32m   7002\u001b[0m     casted \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(item)\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/core/indexes/base.py:7003\u001b[0m, in \u001b[0;36mIndex.insert\u001b[0;34m(self, loc, item)\u001b[0m\n\u001b[1;32m   6996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   6997\u001b[0m     item, (\u001b[38;5;28mtuple\u001b[39m, np\u001b[38;5;241m.\u001b[39mdatetime64, np\u001b[38;5;241m.\u001b[39mtimedelta64)\n\u001b[1;32m   6998\u001b[0m ):\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;66;03m# with object-dtype we need to worry about numpy incorrectly casting\u001b[39;00m\n\u001b[1;32m   7000\u001b[0m     \u001b[38;5;66;03m# dt64/td64 to integer, also about treating tuples as sequences\u001b[39;00m\n\u001b[1;32m   7001\u001b[0m     \u001b[38;5;66;03m# special-casing dt64/td64 https://github.com/numpy/numpy/issues/12550\u001b[39;00m\n\u001b[1;32m   7002\u001b[0m     casted \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(item)\n\u001b[0;32m-> 7003\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7005\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   7006\u001b[0m     \u001b[38;5;66;03m# error: No overload variant of \"insert\" matches argument types\u001b[39;00m\n\u001b[1;32m   7007\u001b[0m     \u001b[38;5;66;03m# \"ndarray[Any, Any]\", \"int\", \"None\"\u001b[39;00m\n\u001b[1;32m   7008\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minsert(arr, loc, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/numpy/lib/function_base.py:5280\u001b[0m, in \u001b[0;36minsert\u001b[0;34m(arr, obj, values, axis)\u001b[0m\n\u001b[1;32m   5278\u001b[0m index \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m   5279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mN \u001b[38;5;129;01mor\u001b[39;00m index \u001b[38;5;241m>\u001b[39m N:\n\u001b[0;32m-> 5280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for axis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5281\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m   5283\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m N\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Define color scheme for architecture types\n",
    "color_scheme = {\n",
    "    \"GNN_MP_transshipment\": \"#ff7f0e\",  # Orange\n",
    "    \"GNN_MP_NN_Per_Layer_transshipment\": \"#2ca02c\",  # Green\n",
    "    \"vanilla_transshipment\": \"#9467bd\",  # Purple\n",
    "}\n",
    "\n",
    "linestyle_scheme = {\n",
    "    \"GNN_MP_transshipment\": \"-\",  # Solid\n",
    "    \"GNN_MP_NN_Per_Layer_transshipment\": \"-\",  # Solid\n",
    "    \"vanilla_transshipment\": \"-\",  # Solid\n",
    "}\n",
    "\n",
    "testset_name = \"generic_architecture_transshipment\"\n",
    "\n",
    "# Define paths for each architecture\n",
    "architectures = {\n",
    "    \"vanilla_transshipment\": {},\n",
    "    \"GNN_MP_transshipment\": {},\n",
    "    \"GNN_MP_NN_Per_Layer_transshipment\": {}\n",
    "}\n",
    "\n",
    "for arch in architectures:\n",
    "    architectures[arch] = {\n",
    "        n_stores: f'/user/ml4723/Prj/NIC/ray_results/{testset_name}/{arch}/{n_stores}'\n",
    "        for n_stores in [3, 5, 10]\n",
    "    }\n",
    "\n",
    "def custom_data_filler(out_row, reference_row):\n",
    "    out_row['path'] = reference_row['path']\n",
    "\n",
    "def default_condition_setter(condition_name):\n",
    "    return None\n",
    "\n",
    "sort_by = 'test_loss'\n",
    "pick_row_from_run_by = 'test_loss'\n",
    "\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "\n",
    "# Create dataframes for each architecture and parameter combination\n",
    "dfs = []\n",
    "params = {\n",
    "    'store_lead_time': [2, 6],\n",
    "    'store_underage_cost': [4, 9],\n",
    "    'stores_correlation': [0.0, 0.5]\n",
    "}\n",
    "\n",
    "for arch_name, paths in architectures.items():\n",
    "    for lead_time in params['store_lead_time']:\n",
    "        for underage_cost in params['store_underage_cost']:\n",
    "            for correlation in params['stores_correlation']:\n",
    "                df = results_interpretor.make_table(paths,\n",
    "                    {'store_lead_time': lead_time,\n",
    "                     'store_underage_cost': underage_cost,\n",
    "                     'stores_correlation': correlation},\n",
    "                    default_condition_setter, custom_data_filler, \n",
    "                    sort_by=sort_by, pick_row_from_run_by=pick_row_from_run_by)\n",
    "                \n",
    "                df.insert(2, 'Architecture Class', arch_name)\n",
    "                df.insert(1, 'hyperparam_name', arch_name)\n",
    "                df['store_lead_time'] = lead_time\n",
    "                df['store_underage_cost'] = underage_cost\n",
    "                df['stores_correlation'] = correlation\n",
    "                dfs.append(df)\n",
    "\n",
    "# Combine all dataframes\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Calculate test gap percentage\n",
    "min_test_loss = df.groupby(['# of stores', 'store_lead_time', 'store_underage_cost', 'stores_correlation'])['Test Loss'].transform('min')\n",
    "df['Test Gap %'] = ((df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "\n",
    "# Create 6 subplots (2x3)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot for each store_lead_time\n",
    "for i, lead_time in enumerate(params['store_lead_time']):\n",
    "    data = df[df['store_lead_time'] == lead_time]\n",
    "    pivot_df = data.groupby(['# of stores', 'Architecture Class'])['Test Gap %'].mean().unstack()\n",
    "    \n",
    "    ax = axes[i]\n",
    "    for arch in pivot_df.columns:\n",
    "        ax.plot(pivot_df.index, pivot_df[arch], \n",
    "                marker='o', label=arch,\n",
    "                color=color_scheme[arch],\n",
    "                linestyle=linestyle_scheme[arch])\n",
    "    ax.set_title(f'Store Lead Time = {lead_time}')\n",
    "    ax.set_xlabel('Number of Stores')\n",
    "    ax.set_ylabel('Test Gap %')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "# Plot for each store_underage_cost\n",
    "for i, underage_cost in enumerate(params['store_underage_cost']):\n",
    "    data = df[df['store_underage_cost'] == underage_cost]\n",
    "    pivot_df = data.groupby(['# of stores', 'Architecture Class'])['Test Gap %'].mean().unstack()\n",
    "    \n",
    "    ax = axes[i+2]\n",
    "    for arch in pivot_df.columns:\n",
    "        ax.plot(pivot_df.index, pivot_df[arch],\n",
    "                marker='o', label=arch,\n",
    "                color=color_scheme[arch],\n",
    "                linestyle=linestyle_scheme[arch])\n",
    "    ax.set_title(f'Store Underage Cost = {underage_cost}')\n",
    "    ax.set_xlabel('Number of Stores')\n",
    "    ax.set_ylabel('Test Gap %')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "# Plot for each stores_correlation\n",
    "for i, correlation in enumerate(params['stores_correlation']):\n",
    "    data = df[df['stores_correlation'] == correlation]\n",
    "    pivot_df = data.groupby(['# of stores', 'Architecture Class'])['Test Gap %'].mean().unstack()\n",
    "    \n",
    "    ax = axes[i+4]\n",
    "    for arch in pivot_df.columns:\n",
    "        ax.plot(pivot_df.index, pivot_df[arch],\n",
    "                marker='o', label=arch,\n",
    "                color=color_scheme[arch],\n",
    "                linestyle=linestyle_scheme[arch])\n",
    "    ax.set_title(f'Store Correlation = {correlation}')\n",
    "    ax.set_xlabel('Number of Stores')\n",
    "    ax.set_ylabel('Test Gap %')\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = collect_data_and_plot(df, \"test\", \"one_warehouse_lost_demand_exp_underage_cost_random_yield\", 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_inventory_control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
