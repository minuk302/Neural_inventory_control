{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic data, one warehouse lost demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import analysis.ray_results_interpreter as rri\n",
    "from importlib import reload\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m results_interpretor \u001b[38;5;241m=\u001b[39m rri\u001b[38;5;241m.\u001b[39mRayResultsinterpreter()\n\u001b[1;32m      8\u001b[0m conditions \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m256\u001b[39m]}\n\u001b[0;32m----> 9\u001b[0m df_ctx \u001b[38;5;241m=\u001b[39m \u001b[43mresults_interpretor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconditions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m df_ctx\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext size\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLearning Rate\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m min_test_loss \u001b[38;5;241m=\u001b[39m df_ctx\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m# of stores\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Prj/NIC/analysis/ray_results_interpreter.py:60\u001b[0m, in \u001b[0;36mRayResultsinterpreter.make_table\u001b[0;34m(self, paths, conditions, custom_data_filler)\u001b[0m\n\u001b[1;32m     58\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_stores, path \u001b[38;5;129;01min\u001b[39;00m paths\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Prj/NIC/analysis/ray_results_interpreter.py:21\u001b[0m, in \u001b[0;36mRayResultsinterpreter.extract_data\u001b[0;34m(self, top_folder)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     data\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(params_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "File \u001b[0;32m~/.conda/envs/neural_inventory_control/lib/python3.10/codecs.py:309\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.__init__\u001b[0;34m(self, errors)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[1;32m    304\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;124;03m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    byte sequences.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 309\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    310\u001b[0m         IncrementalDecoder\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, errors)\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;66;03m# undecoded input that is kept between calls to decode()\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/3\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/10\",\n",
    "    20: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/20\",\n",
    "    50: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/50\"\n",
    "}\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "conditions = {'context': [0, 1, 256]}\n",
    "df_ctx = results_interpretor.make_table(paths, conditions)\n",
    "df_ctx.rename(columns={'context': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "min_test_loss = df_ctx.groupby(['# of stores'])['Test Loss'].transform('min')\n",
    "df_ctx_print = df_ctx.copy()\n",
    "df_ctx_print['Test Gap %'] = ((df_ctx_print['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "print(df_ctx_print.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture Class: GNN\n",
      " # of stores  context size  Learning Rate  Train Loss  Dev Loss  Test Loss  Test Gap %\n",
      "           3             1         0.0100    5.614032  5.609062   5.610129    0.011686\n",
      "           3            16         0.0100    5.618455  5.607520   5.609473    0.000000\n",
      "           3            64         0.0010    5.613282  5.608445   5.609535    0.001103\n",
      "          10             1         0.0100    5.777970  5.816457   5.784590    1.175626\n",
      "          10            16         0.0100    5.708765  5.751087   5.717375    0.000000\n",
      "          10            64         0.0100    5.710389  5.751652   5.717664    0.005067\n",
      "          20             1         0.0010    5.939852  5.911295   5.890847    1.350903\n",
      "          20            16         0.0100    5.841372  5.834482   5.812328    0.000000\n",
      "          20            64         0.0100    5.843079  5.833272   5.812664    0.005784\n",
      "          50             1         0.0001    7.469758  7.450507   9.589425   78.380294\n",
      "          50            16         0.0010    8.678668  8.562173  14.883637  176.862012\n",
      "          50            64         0.0001    5.377279  5.356366   5.375832    0.000000\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/3\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/10\",\n",
    "    20: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/20\",\n",
    "    50: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/50\"\n",
    "}\n",
    "\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "conditions = {'for_all_networks': [1, 16, 64]}\n",
    "df_gnn = results_interpretor.make_table(paths, conditions)\n",
    "df_gnn.rename(columns={'for_all_networks': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "min_test_loss = df_gnn.groupby(['# of stores'])['Test Loss'].transform('min')\n",
    "df_gnn_print = df_gnn.copy()\n",
    "df_gnn_print['Test Gap %'] = ((df_gnn_print['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "print(\"Architecture Class: GNN\")\n",
    "print(df_gnn_print.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture Class: GNN Message Passing\n",
      " # of stores  context size  Learning Rate  Train Loss  Dev Loss  Test Loss  Test Gap %\n",
      "           3             1         0.0100    5.620989  5.612162   5.614612    0.107264\n",
      "           3            16         0.0100    5.613380  5.608589   5.608596    0.000000\n",
      "           3            64         0.0010    5.613815  5.608413   5.609913    0.023482\n",
      "          10             1         0.0100    5.721958  5.761270   5.726167    0.151508\n",
      "          10            16         0.0100    5.711121  5.752939   5.717505    0.000000\n",
      "          10            64         0.0001    5.717989  5.757410   5.722908    0.094494\n",
      "          20             1         0.0010    5.852099  5.842484   5.821487    0.000000\n",
      "          20            16         0.0010    5.853936  5.845516   5.824511    0.051936\n",
      "          20            64         0.0010    5.842828  5.844684   5.822395    0.015586\n",
      "          50             1         0.0100    8.102721  8.089805  10.459843   95.248555\n",
      "          50            16         0.0001    6.305146  6.265387   6.480000   20.958847\n",
      "          50            64         0.0010    5.358920  5.338118   5.357194    0.000000\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/3\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/10\",\n",
    "    20: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/20\",\n",
    "    50: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/50\"\n",
    "}\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "conditions = {'for_all_networks': [1, 16, 64]}\n",
    "df_gnn_mp = results_interpretor.make_table(paths, conditions)\n",
    "df_gnn_mp.rename(columns={'for_all_networks': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "min_test_loss = df_gnn_mp.groupby(['# of stores'])['Test Loss'].transform('min')\n",
    "df_gnn_mp_print = df_gnn_mp.copy()\n",
    "df_gnn_mp_print['Test Gap %'] = ((df_gnn_mp_print['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "print(\"Architecture Class: GNN Message Passing\")\n",
    "print(df_gnn_mp_print.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ctx.insert(1, 'Architecture Class', \"Symmetry_Aware\")\n",
    "df_ctx = df_ctx.loc[df_ctx.groupby(['# of stores'])['Dev Loss'].idxmin()]\n",
    "\n",
    "df_gnn.insert(1, 'Architecture Class', \"GNN\")\n",
    "df_gnn = df_gnn.loc[df_gnn.groupby(['# of stores'])['Dev Loss'].idxmin()]\n",
    "\n",
    "df_gnn_mp.insert(1, 'Architecture Class', \"GNN Message Passing\")\n",
    "df_gnn_mp = df_gnn_mp.loc[df_gnn_mp.groupby(['# of stores'])['Dev Loss'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores  Architecture Class context size  Learning Rate  Train Loss  Dev Loss  Test Loss  Test Gap %\n",
      "           3      Symmetry_Aware            1         0.0100    5.613812  5.608477   5.609850    0.006726\n",
      "           3                 GNN           16         0.0100    5.618455  5.607520   5.609473    0.000000\n",
      "           3 GNN Message Passing           64         0.0010    5.613815  5.608413   5.609913    0.007838\n",
      "           3             Vanilla         None            NaN    5.610000  5.610000   5.610000    0.009392\n",
      "          10      Symmetry_Aware            1         0.0100    5.712263  5.755829   5.720371    0.052401\n",
      "          10                 GNN           16         0.0100    5.708765  5.751087   5.717375    0.000000\n",
      "          10 GNN Message Passing           16         0.0100    5.711121  5.752939   5.717505    0.002278\n",
      "          10             Vanilla         None            NaN    5.720000  5.740000   5.720000    0.045917\n",
      "          20      Symmetry_Aware            1         0.0010    5.850531  5.839253   5.818287    0.096740\n",
      "          20                 GNN           64         0.0100    5.843079  5.833272   5.812664    0.000000\n",
      "          20 GNN Message Passing            1         0.0010    5.852099  5.842484   5.821487    0.151798\n",
      "          20             Vanilla         None            NaN    5.850000  5.870000   5.850000    0.642323\n",
      "          50      Symmetry_Aware          256         0.0010    5.389271  5.366309   5.386096    0.539500\n",
      "          50                 GNN           64         0.0001    5.377279  5.356366   5.375832    0.347911\n",
      "          50 GNN Message Passing           64         0.0010    5.358920  5.338118   5.357194    0.000000\n",
      "          50             Vanilla         None            NaN    5.410000  5.400000   5.420000    1.172372\n"
     ]
    }
   ],
   "source": [
    "vanilla = [\n",
    "    {\n",
    "                \"# of stores\": 3,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.610,\n",
    "                \"Dev Loss\": 5.610,\n",
    "                \"Test Loss\": 5.610,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 10,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.720,\n",
    "                \"Dev Loss\": 5.740,\n",
    "                \"Test Loss\": 5.720,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 20,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.850,\n",
    "                \"Dev Loss\": 5.870,\n",
    "                \"Test Loss\": 5.850,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 50,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.410,\n",
    "                \"Dev Loss\": 5.400,\n",
    "                \"Test Loss\": 5.420,\n",
    "            },\n",
    "]\n",
    "df_vanilla = pd.DataFrame(vanilla)\n",
    "\n",
    "df = pd.concat([df_ctx, df_gnn, df_gnn_mp])\n",
    "architecture_order = ['Symmetry_Aware', 'GNN', 'GNN Message Passing', 'Vanilla']\n",
    "df['Architecture Class'] = pd.Categorical(df['Architecture Class'], categories=architecture_order, ordered=True)\n",
    "min_test_loss = df.groupby(['# of stores'])['Test Loss'].transform('min')\n",
    "df['Test Gap %'] = ((df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "df.sort_values(by=['# of stores', 'Architecture Class'], inplace=True)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic data, Transshipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores Architecture Class context size  Learning Rate  Train Loss  Dev Loss  Test Loss\n",
      "           3     Symmetry_Aware            0         0.0100   15.786119 15.745235  38.493707\n",
      "           3     Symmetry_Aware            1         0.0010    6.451584  6.442219   6.436544\n",
      "           3     Symmetry_Aware          256         0.0100    6.215819  6.195688   6.190809\n",
      "           3            Vanilla         None         0.0001    6.202121  6.195605   6.190790\n",
      "           3        Lower bound         None            NaN         NaN       NaN   6.190000\n",
      "           5     Symmetry_Aware            0         0.0010   14.106193 14.152811  34.056048\n",
      "           5     Symmetry_Aware            1         0.0100    6.061970  6.045415   6.036085\n",
      "           5     Symmetry_Aware          256         0.0010    5.751615  5.759176   5.751703\n",
      "           5            Vanilla         None         0.0001    5.755991  5.759228   5.751869\n",
      "           5        Lower bound         None            NaN         NaN       NaN   5.750000\n",
      "          10     Symmetry_Aware            0         0.0010   14.683252 14.683755  38.511749\n",
      "          10     Symmetry_Aware            1         0.0001    9.254070  9.246135   9.235247\n",
      "          10     Symmetry_Aware          256         0.0010    6.055112  6.058756   6.057758\n",
      "          10            Vanilla         None         0.0001    6.067254  6.073804   6.072607\n",
      "          10        Lower bound         None            NaN         NaN       NaN   6.050000\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/transshipment/3\",\n",
    "    5: \"/user/ml4723/Prj/NIC/ray_results/transshipment/5\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/transshipment/10\",\n",
    "}\n",
    "df_sym = make_the_result_table(paths, [0, 1, 256])\n",
    "df_sym.insert(1, 'Architecture Class', \"Symmetry_Aware\")\n",
    "\n",
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/transshipment/vanilla/3\",\n",
    "    5: \"/user/ml4723/Prj/NIC/ray_results/transshipment/vanilla/5\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/transshipment/vanilla/10\",\n",
    "}\n",
    "df_van = make_the_result_table(paths, [None])\n",
    "df_van.insert(1, 'Architecture Class', \"Vanilla\")\n",
    "\n",
    "lower_bound = [\n",
    "    {\n",
    "                \"# of stores\": 3,\n",
    "                \"Architecture Class\": \"Lower bound\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": None,\n",
    "                \"Dev Loss\": None,\n",
    "                \"Test Loss\": 6.19,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 5,\n",
    "                \"Architecture Class\": \"Lower bound\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": None,\n",
    "                \"Dev Loss\": None,\n",
    "                \"Test Loss\": 5.75,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 10,\n",
    "                \"Architecture Class\": \"Lower bound\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": None,\n",
    "                \"Dev Loss\": None,\n",
    "                \"Test Loss\": 6.05,\n",
    "            },\n",
    "]\n",
    "df_lower_bound = pd.DataFrame(lower_bound)\n",
    "\n",
    "df = pd.concat([df_sym, df_van, df_lower_bound])\n",
    "df.sort_values(by=['# of stores', 'context size'], inplace=True)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One warehouse lost demand synthetic - different primitive setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores  context size  warehouse_holding_cost  warehouse_lead_time  stores_correlation  Learning Rate  Train Loss  Dev Loss  Test Loss  Test Gap %\n",
      "           3             0                     0.7                    6                 0.5          0.010    5.913846  5.907117   5.913744    1.509709\n",
      "           3             1                     0.7                    6                 0.5          0.001    5.843374  5.837429   5.838852    0.224195\n",
      "           3            16                     0.7                    6                 0.5          0.001    5.829509  5.826976   5.827758    0.033756\n",
      "           3            64                     0.7                    6                 0.5          0.001    5.824574  5.827352   5.825791    0.000000\n",
      "           3             0                     1.0                    6                 0.5          0.010    6.003209  5.989507   6.003050    2.219561\n",
      "           3             1                     1.0                    6                 0.5          0.010    5.884676  5.876438   5.877843    0.087556\n",
      "           3            16                     1.0                    6                 0.5          0.001    5.876191  5.872409   5.872701    0.000000\n",
      "           3            64                     1.0                    6                 0.5          0.001    5.874376  5.871622   5.873218    0.008793\n",
      "           3             0                     1.3                    6                 0.5          0.010    6.043122  6.032702   6.045250    2.959561\n",
      "           3             1                     1.3                    6                 0.5          0.010    5.879183  5.875020   5.876117    0.078979\n",
      "           3            16                     1.3                    6                 0.5          0.010    5.871605  5.872480   5.871480    0.000000\n",
      "           3            64                     1.3                    6                 0.5          0.001    5.879224  5.871810   5.872867    0.023625\n",
      "           3             0                     2.0                    6                 0.5          0.010    6.197375  6.143627   6.269510    6.783597\n",
      "           3             1                     2.0                    6                 0.5          0.010    5.896185  5.874366   5.876068    0.082399\n",
      "           3            16                     2.0                    6                 0.5          0.010    5.873271  5.871753   5.871852    0.010600\n",
      "           3            64                     2.0                    6                 0.5          0.001    5.869408  5.871531   5.871230    0.000000\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx'\n",
    "}\n",
    "\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "conditions = {'context': [0, 1, 16, 64], 'warehouse_holding_cost': [0.7, 1.0, 1.3, 2.0], 'warehouse_lead_time': [6], 'stores_correlation': [0.5]}\n",
    "df = results_interpretor.make_table(paths, conditions)\n",
    "df.rename(columns={'context': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "min_test_loss = df.groupby(['warehouse_holding_cost', 'warehouse_lead_time', 'stores_correlation'])['Test Loss'].transform('min')\n",
    "df['Test Gap %'] = ((df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "df.sort_values(by=['warehouse_holding_cost', 'warehouse_lead_time', 'stores_correlation', 'context size'], inplace=True)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'warehouse_holding_cost': [0.7], 'warehouse_lead_time': [6], 'stores_correlation': [0.5]}\n",
      " # of stores Architecture Class  context size  Learning Rate  Train Loss  Dev Loss  Test Loss  # of runs  Test Gap %  best_train_loss\n",
      "           3     Symmatry_Aware           0.0         0.0100    5.913846  5.907117   5.913744         13    1.498100         5.910705\n",
      "           3     Symmatry_Aware           1.0         0.0100    5.838516  5.833413   5.832253         12    0.099469         5.834330\n",
      "           3     Symmatry_Aware          64.0         0.0010    5.830711  5.826821   5.826458         12    0.000000         5.825323\n",
      "           3            Vanilla           NaN         0.0001    5.832769  5.832026   5.832205          6    0.098651         5.822270\n",
      "          10     Symmatry_Aware           0.0         0.0010    6.008479  6.030406   6.007258          6    1.818944         5.996368\n",
      "          10     Symmatry_Aware           1.0         0.0010    5.906434  5.947268   5.906385          6    0.109223         5.903390\n",
      "          10     Symmatry_Aware          64.0         0.0010    5.900517  5.938162   5.899941          6    0.000000         5.888017\n",
      "          10            Vanilla           NaN         0.0001    5.916243  5.956968   5.932895          6    0.558556         5.891574\n",
      "          20     Symmatry_Aware           0.0         0.0001    8.517388  8.445619 315.445125          6 5166.830402         8.478487\n",
      "          20     Symmatry_Aware           1.0         0.0010    7.002570  6.949768   6.974048          6   16.442217         7.002570\n",
      "          20     Symmatry_Aware          64.0         0.0100    6.034117  6.010207   5.989278          6    0.000000         6.026425\n",
      "          20            Vanilla           NaN         0.0001    6.073804  6.046278   6.035570          6    0.772908         6.046983\n",
      "          50     Symmatry_Aware           0.0         0.0010   11.463456 11.455807  12.880835          6  132.481721        11.462973\n",
      "          50     Symmatry_Aware           1.0         0.0001   12.008857 11.976296  12.721058          6  129.597969        12.008857\n",
      "          50     Symmatry_Aware          64.0         0.0001    5.542784  5.523292   5.540580          6    0.000000         5.537093\n",
      "          50            Vanilla           NaN         0.0010    5.573266  5.544857   5.580835          6    0.726553         5.547525\n"
     ]
    }
   ],
   "source": [
    "ctx_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/3',\n",
    "    10: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/10',\n",
    "    20: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/20',\n",
    "    50: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/50'\n",
    "}\n",
    "vanilla_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/vanilla/3',\n",
    "    10: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/vanilla/10',\n",
    "    20: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/vanilla/20',\n",
    "    50: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/vanilla/50'\n",
    "}\n",
    "\n",
    "def custom_data_filler(out_row, reference_row):\n",
    "    out_row['best_train_loss'] = reference_row['best_train_loss']\n",
    "\n",
    "# shared_conditions = {'warehouse_holding_cost': [0.7], 'warehouse_lead_time': [2], 'stores_correlation': [0.5]}\n",
    "# shared_conditions = {'warehouse_holding_cost': [0.7], 'warehouse_lead_time': [6], 'stores_correlation': [0.5]}\n",
    "# shared_conditions = {'warehouse_holding_cost': [1.0], 'warehouse_lead_time': [2], 'stores_correlation': [0.5]}\n",
    "# shared_conditions = {'warehouse_holding_cost': [1.0], 'warehouse_lead_time': [6], 'stores_correlation': [0.5]}\n",
    "\n",
    "condition_for_ctx = shared_conditions.copy()\n",
    "condition_for_ctx['context'] = [0, 1, 64]\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "df_ctx = results_interpretor.make_table(ctx_paths, condition_for_ctx, custom_data_filler)\n",
    "df_ctx.rename(columns={'context': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_vanilla = results_interpretor.make_table(vanilla_paths, shared_conditions, custom_data_filler)\n",
    "df_vanilla.rename(columns={'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_ctx.insert(1, 'Architecture Class', \"Symmatry_Aware\")\n",
    "df_vanilla.insert(1, 'Architecture Class', \"Vanilla\")\n",
    "df = pd.concat([df_ctx, df_vanilla])\n",
    "min_test_loss = df.groupby(['# of stores', 'warehouse_holding_cost', 'warehouse_lead_time', 'stores_correlation'])['Test Loss'].transform('min')\n",
    "df['Test Gap %'] = ((df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "df.insert(df.columns.get_loc(df.columns[-2]), 'Test Gap %', df.pop('Test Gap %'))\n",
    "df.drop(columns=['warehouse_holding_cost', 'warehouse_lead_time', 'stores_correlation'], inplace=True)\n",
    "df.sort_values(by=['# of stores', 'context size'], inplace=True)\n",
    "\n",
    "print(shared_conditions)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores Architecture Class  context size  Learning Rate  Train Loss  Dev Loss  Test Loss  # of runs  Test Gap %  best_train_loss\n",
      "           3     Symmatry_Aware           0.0         0.0100    5.678947  5.667238   5.658443          9    3.297811         5.665088\n",
      "           3     Symmatry_Aware           1.0         0.0100    5.494950  5.499710   5.489791          9    0.218976         5.487189\n",
      "           3     Symmatry_Aware          32.0         0.0010    5.475683  5.493100   5.478564          9    0.014024         5.472106\n",
      "           3     Symmatry_Aware          64.0         0.0001    5.476005  5.493236   5.477796          9    0.000000         5.474725\n",
      "           3            Vanilla           NaN         0.0010    5.485427  5.499762   5.493346         39    0.283868         5.472646\n",
      "           5     Symmatry_Aware           0.0         0.0001    5.292834  5.278422   5.309792          7    3.518935         5.292628\n",
      "           5     Symmatry_Aware           1.0         0.0010    5.114685  5.103980   5.136831          7    0.146904         5.113764\n",
      "           5     Symmatry_Aware          32.0         0.0100    5.105794  5.094029   5.129295          7    0.000000         5.103866\n",
      "           5     Symmatry_Aware          64.0         0.0010    5.104404  5.096772   5.129766          6    0.009177         5.101361\n",
      "           5            Vanilla           NaN         0.0001    5.114913  5.109567   5.145210         10    0.310277         5.111620\n",
      "          20     Symmatry_Aware           0.0         0.0010    5.971279  5.905353   7.352042          9   29.382973         5.965318\n",
      "          20     Symmatry_Aware           1.0         0.0010    5.721358  5.680425   5.687429          9    0.088722         5.718916\n",
      "          20     Symmatry_Aware          32.0         0.0010    5.714095  5.673979   5.687816          9    0.095544         5.707474\n",
      "          20     Symmatry_Aware          64.0         0.0100    5.711388  5.672666   5.682387          9    0.000000         5.694829\n",
      "          20            Vanilla           NaN         0.0001    5.722674  5.700140   5.713550          9    0.548415         5.722674\n",
      "          50     Symmatry_Aware           0.0         0.0010    7.588007  7.393392 133.727600         18 2446.162739         7.476560\n",
      "          50     Symmatry_Aware           1.0         0.0001    5.468956  5.428653   5.473787         18    4.220466         5.466714\n",
      "          50     Symmatry_Aware           2.0         0.0001    7.103422  7.029006   7.081371          9   34.828736         7.092373\n",
      "          50     Symmatry_Aware           4.0         0.0010    6.706720  6.674326   6.715985          9   27.871817         6.706720\n",
      "          50     Symmatry_Aware           8.0         0.0001    5.326957  5.298822  14.920903          9  184.092794         5.326957\n",
      "          50     Symmatry_Aware          16.0         0.0001    5.296885  5.265417   5.303435          9    0.976971         5.294089\n",
      "          50     Symmatry_Aware          32.0         0.0010    5.242711  5.220517   5.257046         18    0.093742         5.238373\n",
      "          50     Symmatry_Aware          64.0         0.0100    5.237406  5.217020   5.252123         18    0.000000         5.233271\n",
      "          50            Vanilla           NaN         0.0001    5.312157  5.273232   5.307982          9    1.063558         5.277625\n",
      "         100     Symmatry_Aware           0.0         0.0001    7.390317  7.347567   7.354566          9   31.270953         7.369595\n",
      "         100     Symmatry_Aware           1.0         0.0010    7.515366  7.397717   7.407649          9   32.218423         7.443486\n",
      "         100     Symmatry_Aware           2.0         0.0001    7.195703  7.170894   7.179658          9   28.149026         7.192712\n",
      "         100     Symmatry_Aware           4.0         0.0001    7.150743  7.130083   7.138766          9   27.419145         7.150071\n",
      "         100     Symmatry_Aware           8.0         0.0010    5.895856  5.877767   5.879652          9    4.945339         5.895856\n",
      "         100     Symmatry_Aware          16.0         0.0001    7.165676  7.145422   7.155942          9   27.725728         7.165676\n",
      "         100     Symmatry_Aware          32.0         0.0001    5.645904  5.629479   5.640435         18    0.675581         5.644966\n",
      "         100     Symmatry_Aware          64.0         0.0010    5.596949  5.594267   5.602585          9    0.000000         5.585413\n",
      "         100            Vanilla           NaN         0.0001    5.652277  5.676761   5.686662          9    1.500682         5.634120\n"
     ]
    }
   ],
   "source": [
    "ctx_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/new_perf/ctx/3',\n",
    "    5: '/user/ml4723/Prj/NIC/ray_results/new_perf/ctx/5',\n",
    "    20: '/user/ml4723/Prj/NIC/ray_results/new_perf/ctx/20',\n",
    "    50: '/user/ml4723/Prj/NIC/ray_results/new_perf/ctx/50',\n",
    "    100: '/user/ml4723/Prj/NIC/ray_results/new_perf/ctx/100'\n",
    "}\n",
    "vanilla_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/new_perf/vanilla/3',\n",
    "    5: '/user/ml4723/Prj/NIC/ray_results/new_perf/vanilla/5',\n",
    "    20: '/user/ml4723/Prj/NIC/ray_results/new_perf/vanilla/20',\n",
    "    50: '/user/ml4723/Prj/NIC/ray_results/new_perf/vanilla/50',\n",
    "    100: '/user/ml4723/Prj/NIC/ray_results/new_perf/vanilla/100'\n",
    "}\n",
    "\n",
    "def custom_data_filler(out_row, reference_row):\n",
    "    out_row['best_train_loss'] = reference_row['best_train_loss']\n",
    "\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "df_ctx = results_interpretor.make_table(ctx_paths, {'context': [0, 1, 2, 4, 8, 16, 32, 64]}, custom_data_filler)\n",
    "df_ctx.rename(columns={'context': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_vanilla = results_interpretor.make_table(vanilla_paths, {}, custom_data_filler)\n",
    "df_vanilla.rename(columns={'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_ctx.insert(1, 'Architecture Class', \"Symmatry_Aware\")\n",
    "df_vanilla.insert(1, 'Architecture Class', \"Vanilla\")\n",
    "df = pd.concat([df_ctx, df_vanilla])\n",
    "min_test_loss = df.groupby(['# of stores'])['Test Loss'].transform('min')\n",
    "df['Test Gap %'] = ((df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "df.insert(df.columns.get_loc(df.columns[-2]), 'Test Gap %', df.pop('Test Gap %'))\n",
    "df.sort_values(by=['# of stores', 'context size'], inplace=True)\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# for 3, 9 from 512 512 512, 0.01, 0.001, 0.0001\n",
    "# 10 from 512, 512, 512, 0.001, 0.0001\n",
    "# 20 from 128, 128, 128, 0.01, 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores Architecture Class  context size  Learning Rate  Train Loss  Dev Loss  Test Loss  # of runs  Test Gap %  best_train_loss\n",
      "           3     Symmatry_Aware           0.0          0.001    5.677065  5.668593   5.659001          5    3.401764         5.670380\n",
      "           3     Symmatry_Aware           1.0          0.010    5.484450  5.489308   5.473140          5    0.005710         5.484236\n",
      "           3     Symmatry_Aware          64.0          0.001    5.480534  5.488657   5.472828          5    0.000000         5.477936\n",
      "           3            Vanilla           NaN          0.001    5.481088  5.490378   5.477924         20    0.093108         5.473786\n"
     ]
    }
   ],
   "source": [
    "ctx_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/new_perf/ctx_large/3',\n",
    "}\n",
    "vanilla_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/new_perf/vanilla_large/3',\n",
    "}\n",
    "\n",
    "def custom_data_filler(out_row, reference_row):\n",
    "    out_row['best_train_loss'] = reference_row['best_train_loss']\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "df_ctx = results_interpretor.make_table(ctx_paths, {'context': [0, 1, 64]}, custom_data_filler)\n",
    "df_ctx.rename(columns={'context': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_vanilla = results_interpretor.make_table(vanilla_paths, {}, custom_data_filler)\n",
    "df_vanilla.rename(columns={'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_ctx.insert(1, 'Architecture Class', \"Symmatry_Aware\")\n",
    "df_vanilla.insert(1, 'Architecture Class', \"Vanilla\")\n",
    "df = pd.concat([df_ctx, df_vanilla])\n",
    "min_test_loss = df.groupby(['# of stores'])['Test Loss'].transform('min')\n",
    "df['Test Gap %'] = ((df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "df.insert(df.columns.get_loc(df.columns[-2]), 'Test Gap %', df.pop('Test Gap %'))\n",
    "df.sort_values(by=['# of stores', 'context size'], inplace=True)\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# for 3, 9 from 512 512 512, 0.01, 0.001, 0.0001\n",
    "# 10 from 512, 512, 512, 0.001, 0.0001\n",
    "# 20 from 128, 128, 128, 0.01, 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores Architecture Class  context size  Learning Rate  Train Loss  Dev Loss  Test Loss  # of runs  Test Gap %  best_train_loss\n",
      "           3     Symmatry_Aware           0.0          0.010    5.924473  5.930560   5.910807          9    1.531933         5.907070\n",
      "           3     Symmatry_Aware           1.0          0.010    5.834254  5.850992   5.821624          9    0.000000         5.823745\n",
      "           3     Symmatry_Aware          64.0          0.010    5.836678  5.855047   5.828812          9    0.123483         5.809814\n",
      "           3            Vanilla           NaN          0.001    5.836746  5.855643   5.823750         25    0.036534         5.796001\n"
     ]
    }
   ],
   "source": [
    "ctx_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/new_perf/ctx_lead/3',\n",
    "}\n",
    "vanilla_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/new_perf/vanilla_lead/3',\n",
    "}\n",
    "\n",
    "def custom_data_filler(out_row, reference_row):\n",
    "    out_row['best_train_loss'] = reference_row['best_train_loss']\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "df_ctx = results_interpretor.make_table(ctx_paths, {'context': [0, 1, 64]}, custom_data_filler)\n",
    "df_ctx.rename(columns={'context': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_vanilla = results_interpretor.make_table(vanilla_paths, {}, custom_data_filler)\n",
    "df_vanilla.rename(columns={'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_ctx.insert(1, 'Architecture Class', \"Symmatry_Aware\")\n",
    "df_vanilla.insert(1, 'Architecture Class', \"Vanilla\")\n",
    "df = pd.concat([df_ctx, df_vanilla])\n",
    "min_test_loss = df.groupby(['# of stores'])['Test Loss'].transform('min')\n",
    "df['Test Gap %'] = ((df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "df.insert(df.columns.get_loc(df.columns[-2]), 'Test Gap %', df.pop('Test Gap %'))\n",
    "df.sort_values(by=['# of stores', 'context size'], inplace=True)\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# for 3, 9 from 512 512 512, 0.01, 0.001, 0.0001\n",
    "# 10 from 512, 512, 512, 0.001, 0.0001\n",
    "# 20 from 128, 128, 128, 0.01, 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores Architecture Class  context size  Learning Rate  Train Loss  Dev Loss  Test Loss  # of runs  Test Gap %  best_train_loss\n",
      "           3     Symmatry_Aware           0.0          0.010    5.939833  5.923935   5.904784          9    1.543459         5.921181\n",
      "           3     Symmatry_Aware           1.0          0.010    5.845350  5.842640   5.815340          9    0.005311         5.841207\n",
      "           3     Symmatry_Aware          64.0          0.010    5.837446  5.845638   5.815469          9    0.007529         5.836145\n",
      "           3            Vanilla           NaN          0.001    5.847357  5.845670   5.815031         10    0.000000         5.836385\n"
     ]
    }
   ],
   "source": [
    "ctx_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/new_perf/ctx_large_lead/3',\n",
    "}\n",
    "vanilla_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/new_perf/vanilla_large_lead/3',\n",
    "}\n",
    "\n",
    "def custom_data_filler(out_row, reference_row):\n",
    "    out_row['best_train_loss'] = reference_row['best_train_loss']\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "df_ctx = results_interpretor.make_table(ctx_paths, {'context': [0, 1, 64]}, custom_data_filler)\n",
    "df_ctx.rename(columns={'context': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_vanilla = results_interpretor.make_table(vanilla_paths, {}, custom_data_filler)\n",
    "df_vanilla.rename(columns={'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_ctx.insert(1, 'Architecture Class', \"Symmatry_Aware\")\n",
    "df_vanilla.insert(1, 'Architecture Class', \"Vanilla\")\n",
    "df = pd.concat([df_ctx, df_vanilla])\n",
    "min_test_loss = df.groupby(['# of stores'])['Test Loss'].transform('min')\n",
    "df['Test Gap %'] = ((df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "df.insert(df.columns.get_loc(df.columns[-2]), 'Test Gap %', df.pop('Test Gap %'))\n",
    "df.sort_values(by=['# of stores', 'context size'], inplace=True)\n",
    "\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# for 3, 9 from 512 512 512, 0.01, 0.001, 0.0001\n",
    "# 10 from 512, 512, 512, 0.001, 0.0001\n",
    "# 20 from 128, 128, 128, 0.01, 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores Architecture Class  context size  Learning Rate  Train Loss  Dev Loss  Test Loss  # of runs  Test Gap %  best_train_loss\n",
      "           3     Symmatry_Aware           0.0          0.010    5.694042  5.685507   5.662421          3    3.401921         5.683701\n",
      "           3     Symmatry_Aware           1.0          0.010    5.551475  5.565333   5.562188          3    1.571570         5.551475\n",
      "           3     Symmatry_Aware          64.0          0.010    5.490902  5.505724   5.476127          2    0.000000         5.490902\n",
      "           3            Vanilla           NaN          0.001    5.519690  5.518813   5.501438         12    0.462204         5.519690\n"
     ]
    }
   ],
   "source": [
    "ctx_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/stable_bench/ctx/3',\n",
    "}\n",
    "vanilla_paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/stable_bench/vanilla/3',\n",
    "}\n",
    "\n",
    "def custom_data_filler(out_row, reference_row):\n",
    "    out_row['best_train_loss'] = reference_row['best_train_loss']\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "df_ctx = results_interpretor.make_table(ctx_paths, {'context': [0, 1, 64]}, custom_data_filler)\n",
    "df_ctx.rename(columns={'context': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_vanilla = results_interpretor.make_table(vanilla_paths, {}, custom_data_filler)\n",
    "df_vanilla.rename(columns={'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "\n",
    "df_ctx.insert(1, 'Architecture Class', \"Symmatry_Aware\")\n",
    "df_vanilla.insert(1, 'Architecture Class', \"Vanilla\")\n",
    "df = pd.concat([df_ctx, df_vanilla])\n",
    "min_test_loss = df.groupby(['# of stores'])['Test Loss'].transform('min')\n",
    "df['Test Gap %'] = ((df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "df.insert(df.columns.get_loc(df.columns[-2]), 'Test Gap %', df.pop('Test Gap %'))\n",
    "df.sort_values(by=['# of stores', 'context size'], inplace=True)\n",
    "\n",
    "print(df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('neural_inventory_control')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "295131613949c3a10f810057b447f8c1d2f9ae56e2b2c791b6162e59dbe65d0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
