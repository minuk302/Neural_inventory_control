{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic data, one warehouse lost demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import analysis.ray_results_interpreter as rri\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores  context size  Learning Rate  Train Loss  Dev Loss  Test Loss\n",
      "           3             0         0.0100    5.670470  5.657994   5.663223\n",
      "           3             1         0.0100    5.613812  5.608477   5.609850\n",
      "           3           256         0.0100    5.616237  5.611364   5.612627\n",
      "           5             0         0.0010    5.312334  5.292432   5.301958\n",
      "           5             1         0.0100    5.256996  5.235224   5.247245\n",
      "           5           256         0.0001    5.249202  5.237397   5.249729\n",
      "          10             0         0.0100    5.773343  5.808772   5.776743\n",
      "          10             1         0.0100    5.712263  5.755829   5.720371\n",
      "          10           256         0.0100    5.731197  5.761904   5.729029\n",
      "          20             0         0.0010    5.902905  5.892253   5.871639\n",
      "          20             1         0.0010    5.850531  5.839253   5.818287\n",
      "          20           256         0.0100    5.857646  5.844117   5.820630\n",
      "          30             0         0.0010    5.600722  5.605764   5.601543\n",
      "          30             1         0.0010    5.548159  5.556480   5.550539\n",
      "          30           256         0.0100    5.569959  5.574575   5.569556\n",
      "          50             0         0.0001    6.545030  6.524776   6.538479\n",
      "          50             1         0.0001    6.759303  6.723869   6.789614\n",
      "          50           256         0.0010    5.389271  5.366309   5.386096\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/3\",\n",
    "    5: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/5\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/10\",\n",
    "    20: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/20\",\n",
    "    30: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/30\",\n",
    "    50: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/50\"\n",
    "}\n",
    "conditions = {'context': [0, 1, 256]}\n",
    "df = results_interpretor.make_table(paths, conditions)\n",
    "df.rename(columns={'context': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores  context size  Learning Rate  Train Loss  Dev Loss  Test Loss\n",
      "           3             1           0.01    5.623115  5.613710   5.616462\n",
      "           3            16           0.01    5.618455  5.607520   5.609473\n",
      "           3            64           0.01    5.616272  5.608735   5.608330\n",
      "          10             1           0.01    5.805394  5.818976   5.786214\n",
      "          10            16           0.01    5.708765  5.751087   5.717375\n",
      "          10            64           0.01    5.712751  5.752891   5.718822\n",
      "          20             1           0.01   15.638020 15.544399  15.692766\n",
      "          20            16           0.01    5.841372  5.834482   5.812328\n",
      "          50             1           0.01   11.232640 11.216736  11.230151\n",
      "          50            16           0.01   13.213552 13.178728  14.110262\n",
      "          50            64           0.01   22.270393 22.313019  30.210777\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/3\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/10\",\n",
    "    20: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/20\",\n",
    "    50: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/50\"\n",
    "}\n",
    "\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "conditions = {'for_all_networks': [1, 16, 64]}\n",
    "df = results_interpretor.make_table(paths, conditions)\n",
    "df.rename(columns={'for_all_networks': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores  context size  Learning Rate  Train Loss  Dev Loss  Test Loss\n",
      "           3             1          0.010    5.623565  5.616145   5.620568\n",
      "           3            16          0.010    5.613380  5.608589   5.608596\n",
      "           3            64          0.010    5.614989  5.612327   5.613634\n",
      "          10             1          0.001    5.728411  5.772287   5.738262\n",
      "          10            16          0.010    5.711121  5.752939   5.717505\n",
      "          10            64          0.010    5.771418  5.807780   5.775408\n",
      "          20             1          0.001    5.922441  5.902557   5.882965\n",
      "          20            16          0.001    6.475514  6.416679   6.434179\n",
      "          20            64          0.010    5.905616  5.888665   5.869436\n",
      "          50             1          0.010    8.102721  8.089805  10.459843\n",
      "          50            16          0.001    6.631942  6.602454   6.568062\n",
      "          50            64          0.001    5.358920  5.338118   5.357194\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/3\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/10\",\n",
    "    20: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/20\",\n",
    "    50: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/50\"\n",
    "}\n",
    "results_interpretor = rri.RayResultsinterpreter()\n",
    "conditions = {'for_all_networks': [1, 16, 64]}\n",
    "df = results_interpretor.make_table(paths, conditions)\n",
    "df.rename(columns={'for_all_networks': 'context size', 'learning_rate': 'Learning Rate'}, inplace=True)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/50/run_2024-07-30_04-49-05/run_93d51_00022_22_for_all_networks=64,learning_rate=0.0001,samples=0_2024-07-30_04-49-06: Expecting value: line 1 column 1 (char 0)\n",
      "Error processing files in /user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/50/run_2024-07-30_04-49-05/run_93d51_00002_2_for_all_networks=4,learning_rate=0.0100,samples=0_2024-07-30_04-49-06: No columns to parse from file\n",
      " # of stores  Architecture Class context size  Learning Rate  Train Loss  Dev Loss  Test Loss\n",
      "           3      Symmetry_Aware            1          0.010    5.613812  5.608477   5.609850\n",
      "           3                 GNN            8          0.010    5.615963  5.607577   5.610156\n",
      "           3 GNN Message Passing            4          0.010    5.615473  5.608413   5.608291\n",
      "           3             Vanilla         None            NaN    5.610000  5.610000   5.610000\n",
      "           5      Symmetry_Aware            1          0.010    5.256996  5.235224   5.247245\n",
      "           5                 GNN            8          0.010    5.254034  5.232832   5.244306\n",
      "           5 GNN Message Passing            4          0.010    5.252546  5.233202   5.243820\n",
      "           5             Vanilla         None            NaN    5.250000  5.250000   5.240000\n",
      "          10      Symmetry_Aware            1          0.010    5.712263  5.755829   5.720371\n",
      "          10                 GNN            8          0.010    5.711636  5.750974   5.716066\n",
      "          10 GNN Message Passing            4          0.010    5.708307  5.751485   5.717671\n",
      "          10             Vanilla         None            NaN    5.720000  5.740000   5.720000\n",
      "          20      Symmetry_Aware            1          0.001    5.850531  5.839253   5.818287\n",
      "          20                 GNN           16          0.010    5.849595  5.847377   5.821361\n",
      "          20 GNN Message Passing           64          0.010    5.905119  5.890425   5.869727\n",
      "          20             Vanilla         None            NaN    5.850000  5.870000   5.850000\n",
      "          30      Symmetry_Aware            1          0.001    5.548159  5.556480   5.550539\n",
      "          30                 GNN          128          0.010    5.541947  5.549635   5.546000\n",
      "          30 GNN Message Passing           16          0.001    5.540921  5.549885   5.546176\n",
      "          30             Vanilla         None            NaN    5.580000  5.600000   5.590000\n",
      "          50      Symmetry_Aware          256          0.001    5.389271  5.366309   5.386096\n",
      "          50                 GNN            4          0.010    8.126138  8.116012 294.221387\n",
      "          50 GNN Message Passing          128          0.001    5.354713  5.342200   5.360307\n",
      "          50             Vanilla         None            NaN    5.410000  5.400000   5.420000\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/3\",\n",
    "    5: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/5\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/10\",\n",
    "    20: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/20\",\n",
    "    30: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/30\",\n",
    "    50: \"/user/ml4723/Prj/NIC/ray_results/perf/ctx/50\"\n",
    "}\n",
    "df_ctx = make_the_result_table(paths, [0, 1, 256])\n",
    "df_ctx.insert(1, 'Architecture Class', \"Symmetry_Aware\")\n",
    "df_ctx = df_ctx.loc[df_ctx.groupby(['# of stores'])['Dev Loss'].idxmin()]\n",
    "\n",
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/3\",\n",
    "    5: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/5\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/10\",\n",
    "    20: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/20\",\n",
    "    30: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/30\",\n",
    "    50: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN/50\"\n",
    "}\n",
    "df_gnn = make_the_result_table(paths, [1, 2, 4, 8, 16, 32, 64, 128])\n",
    "df_gnn.insert(1, 'Architecture Class', \"GNN\")\n",
    "df_gnn = df_gnn.loc[df_gnn.groupby(['# of stores'])['Dev Loss'].idxmin()]\n",
    "\n",
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/3\",\n",
    "    5: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/5\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/10\",\n",
    "    20: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/20\",\n",
    "    30: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/30\",\n",
    "    50: \"/user/ml4723/Prj/NIC/ray_results/perf/GNN_message_passing/50\"\n",
    "}\n",
    "df_gnn_mp = make_the_result_table(paths, [1, 2, 4, 8, 16, 32, 64, 128])\n",
    "df_gnn_mp.insert(1, 'Architecture Class', \"GNN Message Passing\")\n",
    "df_gnn_mp = df_gnn_mp.loc[df_gnn_mp.groupby(['# of stores'])['Dev Loss'].idxmin()]\n",
    "\n",
    "vanilla = [\n",
    "    {\n",
    "                \"# of stores\": 3,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.610,\n",
    "                \"Dev Loss\": 5.610,\n",
    "                \"Test Loss\": 5.610,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 5,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.250,\n",
    "                \"Dev Loss\": 5.250,\n",
    "                \"Test Loss\": 5.240,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 10,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.720,\n",
    "                \"Dev Loss\": 5.740,\n",
    "                \"Test Loss\": 5.720,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 20,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.850,\n",
    "                \"Dev Loss\": 5.870,\n",
    "                \"Test Loss\": 5.850,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 30,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.580,\n",
    "                \"Dev Loss\": 5.60,\n",
    "                \"Test Loss\": 5.59,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 50,\n",
    "                \"Architecture Class\": \"Vanilla\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": 5.410,\n",
    "                \"Dev Loss\": 5.400,\n",
    "                \"Test Loss\": 5.420,\n",
    "            },\n",
    "]\n",
    "df_vanilla = pd.DataFrame(vanilla)\n",
    "\n",
    "df = pd.concat([df_ctx, df_gnn, df_gnn_mp, df_vanilla])\n",
    "architecture_order = ['Symmetry_Aware', 'GNN', 'GNN Message Passing', 'Vanilla']\n",
    "df['Architecture Class'] = pd.Categorical(df['Architecture Class'], categories=architecture_order, ordered=True)\n",
    "df.sort_values(by=['# of stores', 'Architecture Class'], inplace=True)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synthetic data, Transshipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # of stores Architecture Class context size  Learning Rate  Train Loss  Dev Loss  Test Loss\n",
      "           3     Symmetry_Aware            0         0.0100   15.786119 15.745235  38.493707\n",
      "           3     Symmetry_Aware            1         0.0010    6.451584  6.442219   6.436544\n",
      "           3     Symmetry_Aware          256         0.0100    6.215819  6.195688   6.190809\n",
      "           3            Vanilla         None         0.0001    6.202121  6.195605   6.190790\n",
      "           3        Lower bound         None            NaN         NaN       NaN   6.190000\n",
      "           5     Symmetry_Aware            0         0.0010   14.106193 14.152811  34.056048\n",
      "           5     Symmetry_Aware            1         0.0100    6.061970  6.045415   6.036085\n",
      "           5     Symmetry_Aware          256         0.0010    5.751615  5.759176   5.751703\n",
      "           5            Vanilla         None         0.0001    5.755991  5.759228   5.751869\n",
      "           5        Lower bound         None            NaN         NaN       NaN   5.750000\n",
      "          10     Symmetry_Aware            0         0.0010   14.683252 14.683755  38.511749\n",
      "          10     Symmetry_Aware            1         0.0001    9.254070  9.246135   9.235247\n",
      "          10     Symmetry_Aware          256         0.0010    6.055112  6.058756   6.057758\n",
      "          10            Vanilla         None         0.0001    6.067254  6.073804   6.072607\n",
      "          10        Lower bound         None            NaN         NaN       NaN   6.050000\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/transshipment/3\",\n",
    "    5: \"/user/ml4723/Prj/NIC/ray_results/transshipment/5\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/transshipment/10\",\n",
    "}\n",
    "df_sym = make_the_result_table(paths, [0, 1, 256])\n",
    "df_sym.insert(1, 'Architecture Class', \"Symmetry_Aware\")\n",
    "\n",
    "paths = {\n",
    "    3: \"/user/ml4723/Prj/NIC/ray_results/transshipment/vanilla/3\",\n",
    "    5: \"/user/ml4723/Prj/NIC/ray_results/transshipment/vanilla/5\",\n",
    "    10: \"/user/ml4723/Prj/NIC/ray_results/transshipment/vanilla/10\",\n",
    "}\n",
    "df_van = make_the_result_table(paths, [None])\n",
    "df_van.insert(1, 'Architecture Class', \"Vanilla\")\n",
    "\n",
    "lower_bound = [\n",
    "    {\n",
    "                \"# of stores\": 3,\n",
    "                \"Architecture Class\": \"Lower bound\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": None,\n",
    "                \"Dev Loss\": None,\n",
    "                \"Test Loss\": 6.19,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 5,\n",
    "                \"Architecture Class\": \"Lower bound\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": None,\n",
    "                \"Dev Loss\": None,\n",
    "                \"Test Loss\": 5.75,\n",
    "            },\n",
    "    {\n",
    "                \"# of stores\": 10,\n",
    "                \"Architecture Class\": \"Lower bound\",\n",
    "                \"context size\": None,\n",
    "                \"Learning Rate\": None,\n",
    "                \"Train Loss\": None,\n",
    "                \"Dev Loss\": None,\n",
    "                \"Test Loss\": 6.05,\n",
    "            },\n",
    "]\n",
    "df_lower_bound = pd.DataFrame(lower_bound)\n",
    "\n",
    "df = pd.concat([df_sym, df_van, df_lower_bound])\n",
    "df.sort_values(by=['# of stores', 'context size'], inplace=True)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One warehouse lost demand synthetic - different primitive setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_the_result_table_diff_primitive(paths, context_sizes, warehouse_holding_costs, warehouse_lead_times, stores_correlations):\n",
    "    # Placeholder for results\n",
    "    results = []\n",
    "\n",
    "    # Iterate over each path and context size, call the function, and store the top row\n",
    "    for num_stores, path in paths.items():\n",
    "        for context_size in context_sizes:\n",
    "            df = create_results_table(path, context_size)\n",
    "            if df is None:\n",
    "                continue\n",
    "            for warehouse_holding_cost in warehouse_holding_costs:\n",
    "                df_hc = df[df['warehouse_holding_cost'] == warehouse_holding_cost]\n",
    "                if df_hc.empty:\n",
    "                    continue\n",
    "                for warehouse_lead_time in warehouse_lead_times:\n",
    "                    df_hl = df_hc[df_hc['warehouse_lead_time'] == warehouse_lead_time]\n",
    "                    if df_hl.empty:\n",
    "                        continue\n",
    "                    for stores_correlation in stores_correlations:\n",
    "                        df_sc = df_hl[df_hl['stores_correlation'] == stores_correlation]\n",
    "                        if df_sc.empty:\n",
    "                            continue\n",
    "                        top_row = df_sc.iloc[0]\n",
    "                        result_row = {\n",
    "                            'warehouse_holding_cost': top_row['warehouse_holding_cost'],\n",
    "                            'warehouse_lead_time': top_row['warehouse_lead_time'],\n",
    "                            'stores_correlation': top_row['stores_correlation'],\n",
    "                            \"context size\": context_size,\n",
    "                            \"Learning Rate\": top_row['learning_rate'],\n",
    "                            \"Train Loss\": top_row['train_loss(at best_dev)'],\n",
    "                            \"Dev Loss\": top_row['best_dev_loss'],\n",
    "                            \"Test Loss\": top_row['test_loss(at best_dev)'],\n",
    "                            \"path\": top_row['path'],\n",
    "                        }\n",
    "                        results.append(result_row)\n",
    "    result_df = pd.DataFrame(results)\n",
    "    min_test_loss = result_df.groupby(['warehouse_holding_cost', 'warehouse_lead_time', 'stores_correlation'])['Test Loss'].transform('min')\n",
    "    result_df['Test Gap %'] = ((result_df['Test Loss'] - min_test_loss) / min_test_loss) * 100\n",
    "    result_df.sort_values(by=['warehouse_holding_cost', 'warehouse_lead_time', 'stores_correlation', 'context size'], inplace=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " warehouse_holding_cost  warehouse_lead_time  stores_correlation  context size  Learning Rate  Train Loss  Dev Loss  Test Loss                                                                                                                                                                                      path  Test Gap %\n",
      "                    0.7                    6                 0.5             0          0.010    5.913846  5.907117   5.913744 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-41-23/run_e7229_00012_12_context=0,learning_rate=0.0100,samples=2,warehouse_holding_cost=0.7000_2024-07-31_02-41-23    1.509709\n",
      "                    0.7                    6                 0.5             1          0.001    5.843374  5.837429   5.838852  /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-41-23/run_e7229_00005_5_context=1,learning_rate=0.0010,samples=1,warehouse_holding_cost=0.7000_2024-07-31_02-41-23    0.224195\n",
      "                    0.7                    6                 0.5            16          0.001    5.829509  5.826976   5.827758 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-41-23/run_e7229_00006_6_context=16,learning_rate=0.0010,samples=1,warehouse_holding_cost=0.7000_2024-07-31_02-41-23    0.033756\n",
      "                    0.7                    6                 0.5            64          0.001    5.824574  5.827352   5.825791 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-41-23/run_e7229_00007_7_context=64,learning_rate=0.0010,samples=1,warehouse_holding_cost=0.7000_2024-07-31_02-41-23    0.000000\n",
      "                    1.0                    6                 0.5             0          0.010    6.003209  5.989507   6.003050  /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-43-31/run_33d8f_00000_0_context=0,learning_rate=0.0100,samples=1,warehouse_holding_cost=1.0000_2024-07-31_02-43-32    2.219561\n",
      "                    1.0                    6                 0.5             1          0.010    5.891307  5.879282   5.881262 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-43-31/run_33d8f_00013_13_context=1,learning_rate=0.0100,samples=2,warehouse_holding_cost=1.0000_2024-07-31_02-43-32    0.145762\n",
      "                    1.0                    6                 0.5            16          0.001    5.876191  5.872409   5.872701 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-43-31/run_33d8f_00006_6_context=16,learning_rate=0.0010,samples=1,warehouse_holding_cost=1.0000_2024-07-31_02-43-32    0.000000\n",
      "                    1.0                    6                 0.5            64          0.001    5.874376  5.871622   5.873218 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-43-31/run_33d8f_00007_7_context=64,learning_rate=0.0010,samples=1,warehouse_holding_cost=1.0000_2024-07-31_02-43-32    0.008793\n",
      "                    1.3                    6                 0.5             0          0.010    6.043122  6.032702   6.045250 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_01-37-33/run_fc58a_00012_12_context=0,learning_rate=0.0100,samples=2,warehouse_holding_cost=1.3000_2024-07-31_01-37-33    2.959561\n",
      "                    1.3                    6                 0.5             1          0.010    5.879183  5.875020   5.876117 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_01-37-33/run_fc58a_00013_13_context=1,learning_rate=0.0100,samples=2,warehouse_holding_cost=1.3000_2024-07-31_01-37-33    0.078979\n",
      "                    1.3                    6                 0.5            16          0.010    5.871605  5.872480   5.871480 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_01-37-33/run_fc58a_00002_2_context=16,learning_rate=0.0100,samples=1,warehouse_holding_cost=1.3000_2024-07-31_01-37-33    0.000000\n",
      "                    1.3                    6                 0.5            64          0.001    5.879224  5.871810   5.872867 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_01-37-33/run_fc58a_00007_7_context=64,learning_rate=0.0010,samples=1,warehouse_holding_cost=1.3000_2024-07-31_01-37-33    0.023625\n",
      "                    2.0                    6                 0.5             0          0.010    6.197375  6.143627   6.269510 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-01-22/run_5012f_00012_12_context=0,learning_rate=0.0100,samples=2,warehouse_holding_cost=2.0000_2024-07-31_02-01-22    6.783597\n",
      "                    2.0                    6                 0.5             1          0.010    5.896185  5.874366   5.876068  /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-01-22/run_5012f_00001_1_context=1,learning_rate=0.0100,samples=1,warehouse_holding_cost=2.0000_2024-07-31_02-01-22    0.082399\n",
      "                    2.0                    6                 0.5            16          0.010    5.873271  5.871753   5.871852 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-01-22/run_5012f_00002_2_context=16,learning_rate=0.0100,samples=1,warehouse_holding_cost=2.0000_2024-07-31_02-01-22    0.010600\n",
      "                    2.0                    6                 0.5            64          0.001    5.869408  5.871531   5.871230 /user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx/run_2024-07-31_02-01-22/run_5012f_00007_7_context=64,learning_rate=0.0010,samples=1,warehouse_holding_cost=2.0000_2024-07-31_02-01-22    0.000000\n"
     ]
    }
   ],
   "source": [
    "paths = {\n",
    "    3: '/user/ml4723/Prj/NIC/ray_results/diff_primitive/ctx'\n",
    "}\n",
    "\n",
    "# df = make_the_result_table_diff_primitive(paths, [0, 1, 16, 64], [0.7, 1.0, 1.3, 2.0], [2, 6], [-0.5, 0.0, 0.5])\n",
    "df = make_the_result_table_diff_primitive(paths, [0, 1, 16, 64], [0.7, 1.0, 1.3, 2.0], [6], [0.5])\n",
    "print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('neural_inventory_control')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "295131613949c3a10f810057b447f8c1d2f9ae56e2b2c791b6162e59dbe65d0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
